{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import mne\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "from gait_modulation import MatFileReader, DataProcessor, Visualise, FeatureExtractor\n",
    "from gait_modulation import BaseModel, LogisticRegressionModel, LSTMModel\n",
    "from gait_modulation.utils.utils import split_data, load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File does not exist: \"/Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/gait_modulation/processd/lfp_-3.0tmin_5gap-epo.fif\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[43mmne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprocessd/lfp_-3.0tmin_5gap-epo.fif\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m epochs\u001b[38;5;241m.\u001b[39mget_data(copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m<decorator-gen-250>:12\u001b[0m, in \u001b[0;36mread_epochs\u001b[0;34m(fname, proj, preload, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/gait_modulation/lib/python3.10/site-packages/mne/epochs.py:4219\u001b[0m, in \u001b[0;36mread_epochs\u001b[0;34m(fname, proj, preload, verbose)\u001b[0m\n\u001b[1;32m   4201\u001b[0m \u001b[38;5;129m@verbose\u001b[39m\n\u001b[1;32m   4202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_epochs\u001b[39m(fname, proj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, preload\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochsFIF\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   4203\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read epochs from a fif file.\u001b[39;00m\n\u001b[1;32m   4204\u001b[0m \n\u001b[1;32m   4205\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4217\u001b[0m \u001b[38;5;124;03m        The epochs.\u001b[39;00m\n\u001b[1;32m   4218\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mEpochsFIF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<decorator-gen-251>:12\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, fname, proj, preload, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/gait_modulation/lib/python3.10/site-packages/mne/epochs.py:4268\u001b[0m, in \u001b[0;36mEpochsFIF.__init__\u001b[0;34m(self, fname, proj, preload, verbose)\u001b[0m\n\u001b[1;32m   4262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _path_like(fname):\n\u001b[1;32m   4263\u001b[0m     check_fname(\n\u001b[1;32m   4264\u001b[0m         fname\u001b[38;5;241m=\u001b[39mfname,\n\u001b[1;32m   4265\u001b[0m         filetype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4266\u001b[0m         endings\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-epo.fif\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-epo.fif.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_epo.fif\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_epo.fif.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   4267\u001b[0m     )\n\u001b[0;32m-> 4268\u001b[0m     fname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43m_check_fname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmust_exist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mread\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   4269\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m preload:\n\u001b[1;32m   4270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreload must be used with file-like objects\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m<decorator-gen-0>:12\u001b[0m, in \u001b[0;36m_check_fname\u001b[0;34m(fname, overwrite, must_exist, name, need_dir, check_bids_split, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/gait_modulation/lib/python3.10/site-packages/mne/utils/check.py:280\u001b[0m, in \u001b[0;36m_check_fname\u001b[0;34m(fname, overwrite, must_exist, name, need_dir, check_bids_split, verbose)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mPermissionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not have read permissions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m must_exist:\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fname\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File does not exist: \"/Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/gait_modulation/processd/lfp_-3.0tmin_5gap-epo.fif\""
     ]
    }
   ],
   "source": [
    "epochs = mne.read_epochs('processed/lfp_-3.0tmin_5gap-epo.fif')\n",
    "epochs.get_data(copy=False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_bands = {\n",
    "    'delta': (0.1, 3),\n",
    "    'theta': (4, 7),\n",
    "    'alpha': (8, 12),\n",
    "    'low_beta': (12, 16),\n",
    "    'middle_beta': (16, 20),\n",
    "    'high_beta': (20, 30),\n",
    "    'gamma': (30, 100),\n",
    "    'high_gamma': (100, 125)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Create model instances\n",
    "logreg_model = LogisticRegressionModel()\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "# splits: X_train, X_test, y_train, y_test\n",
    "logreg_model.evaluate(splits)\n",
    "\n",
    "# After cross-validation, retrain on the best evaluation split (zero's split) : fit(X_train, y_train)\n",
    "# logreg_model.fit(splits[0][0], splits[0][2])\n",
    "\n",
    "# prediction on test data: predict(X_test)\n",
    "y_pred = logreg_model.predict(splits[0][1])\n",
    "print(\"GT:\", splits[0][3])\n",
    "print(\"Predictions:\", y_pred)\n",
    "\n",
    "# plt.scatter(np.arange(splits[0][3].shape[0]), splits[0][3])\n",
    "# plt.scatter(np.arange(y_pred.shape[0]), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# def visualize_predictions(y_true, y_pred, fold=None):\n",
    "#     \"\"\"\n",
    "#     Visualize and compare predictions with true labels.\n",
    "    \n",
    "#     Args:\n",
    "#     - y_true: True labels\n",
    "#     - y_pred: Predicted labels\n",
    "#     - fold: (optional) Current fold number, for cross-validation context\n",
    "#     \"\"\"\n",
    "#     # Confusion Matrix\n",
    "#     cm = confusion_matrix(y_true, y_pred)\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "#     plt.xlabel('Predicted Labels')\n",
    "#     plt.ylabel('True Labels')\n",
    "#     title = f\"Confusion Matrix for Fold {fold}\" if fold else \"Confusion Matrix\"\n",
    "#     plt.title(title)\n",
    "#     plt.show()\n",
    "\n",
    "#     # Distribution of Predictions\n",
    "#     plt.figure(figsize=(8, 4))\n",
    "#     sns.histplot(y_pred, color=\"blue\", alpha=0.6, kde=True, label=\"Predicted\")\n",
    "#     sns.histplot(y_true, color=\"green\", alpha=0.6, kde=True, label=\"True\")\n",
    "#     plt.xlabel(\"Class Labels\")\n",
    "#     plt.legend()\n",
    "#     title = f\"Prediction Distribution for Fold {fold}\" if fold else \"Prediction Distribution\"\n",
    "#     plt.title(title)\n",
    "#     plt.show()\n",
    "\n",
    "#     # Plot Actual vs. Predicted Labels\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.plot(y_true, label=\"True Labels\", marker='o', linestyle='')\n",
    "#     plt.plot(y_pred, label=\"Predicted Labels\", marker='x', linestyle='')\n",
    "#     plt.xlabel(\"Sample Index\")\n",
    "#     plt.ylabel(\"Class Label\")\n",
    "#     plt.legend()\n",
    "#     title = f\"Actual vs. Predicted Labels for Fold {fold}\" if fold else \"Actual vs. Predicted Labels\"\n",
    "#     plt.title(title)\n",
    "#     plt.show()\n",
    "\n",
    "# # Example usage in cross-validation loop\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# # Assuming X, y are your features and labels\n",
    "# n_splits = 5\n",
    "# kf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "# accuracies = []\n",
    "\n",
    "# for fold, (train_index, test_index) in enumerate(kf.split(X, y), start=1):\n",
    "#     # Split data\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "#     # Train model and get predictions\n",
    "#     model = LogisticRegressionModel()  # Example model\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "\n",
    "#     # Calculate accuracy\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     accuracies.append(accuracy)\n",
    "#     print(f\"Fold {fold} - Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "#     # Visualize predictions for the current fold\n",
    "#     visualize_predictions(y_test, y_pred, fold=fold)\n",
    "\n",
    "# # Plot Accuracy Over Folds\n",
    "# plt.figure(figsize=(8, 4))\n",
    "# plt.plot(range(1, n_splits + 1), accuracies, marker='o')\n",
    "# plt.title(\"Model Accuracy Across Folds\")\n",
    "# plt.xlabel(\"Fold\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.xticks(range(1, n_splits + 1))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LSTMModel' from 'gait_modulation.models.base_model' (/Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/gait_modulation/gait_modulation/models/base_model.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgait_modulation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTMModel\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Create model instances\u001b[39;00m\n\u001b[1;32m      4\u001b[0m lstm_model \u001b[38;5;241m=\u001b[39m LSTMModel()\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'LSTMModel' from 'gait_modulation.models.base_model' (/Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/gait_modulation/gait_modulation/models/base_model.py)"
     ]
    }
   ],
   "source": [
    "from gait_modulation.models.base_model import LSTMModel\n",
    "\n",
    "# Create model instances\n",
    "lstm_model = LSTMModel()\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "# splits: X_train, X_test, y_train, y_test\n",
    "lstm_model.evaluate(splits, len(freq_bands))\n",
    "# After cross-validation, retrain on the best evaluation split (zero's split) : fit(X_train, y_train)\n",
    "# lstm_model.fit(splits[0][0], splits[0][2])\n",
    "\n",
    "# prediction on test data: predict(X_test)\n",
    "y_pred = lstm_model.predict(splits[0][1])\n",
    "print(\"GT:\", splits[0][3])\n",
    "print(\"Predictions:\", y_pred)\n",
    "\n",
    "# plt.scatter(np.arange(splits[0][3].shape[0]), splits[0][3])\n",
    "# plt.scatter(np.arange(y_pred.shape[0]), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to do it for another model, like LSTM:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models with cross-validation\n",
    "\n",
    "# # The evaluation function remains the same as before\n",
    "# models, indices = train_logistic_regression_with_cv(combined_psds_bandPower, labels)\n",
    "\n",
    "# # Evaluate trained models\n",
    "# metrics = evaluate_models(models, combined_psds_bandPower, labels, indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.evaluate(combined_psds_bandPower2.reshape(combined_psds_bandPower2.shape[0], -1), labels2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Initialize metrics dictionary\n",
    "metrics = {\n",
    "    'accuracy': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'f1': [],\n",
    "    'confusion_matrices': []\n",
    "}\n",
    "\n",
    "# Reshape combined_data for LSTM input\n",
    "# Reshape into (n_samples, time_steps, n_features)\n",
    "# Here, we treat the whole feature set as a single time step.\n",
    "X_reshaped = combined_psds_bandPower.reshape(combined_psds_bandPower.shape[0],\n",
    "                                             1, \n",
    "                                             combined_psds_bandPower.shape[1])\n",
    "\n",
    "# Generate labels\n",
    "labels = np.concatenate((np.ones(psds_bandPower_mod_start.shape[0]),\n",
    "                         np.zeros(psds_bandPower_normal_walking.shape[0])), axis=0)\n",
    "\n",
    "def create_model(input_shape, learning_rate=0.0005):\n",
    "    \"\"\"\n",
    "    Create and compile an LSTM model with dropout layers and focal loss.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_shape: Tuple representing the shape of the input data.\n",
    "    \n",
    "    Returns:\n",
    "    - model: Compiled LSTM model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=input_shape, return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Optimizer with a reduced learning rate\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=focal_loss(gamma=2, alpha=0.25), optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def focal_loss(gamma=2., alpha=0.75):\n",
    "    \"\"\"\n",
    "    Custom focal loss function to handle class imbalance.\n",
    "    \n",
    "    Parameters:\n",
    "    - gamma: Focusing parameter for focal loss.\n",
    "    - alpha: Balancing factor for classes.\n",
    "    \n",
    "    Returns:\n",
    "    - focal_loss_fixed: Focal loss function\n",
    "    \"\"\"\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_true = K.cast(y_true, dtype='float32')\n",
    "        alpha_t = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
    "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        fl = -alpha_t * K.pow(1. - p_t, gamma) * K.log(p_t + K.epsilon())\n",
    "        return K.mean(fl)\n",
    "    return focal_loss_fixed\n",
    "\n",
    "# Stratified K-Fold Cross-Validation\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for train_index, test_index in kf.split(X_reshaped, labels):\n",
    "    X_train, X_test = X_reshaped[train_index], X_reshaped[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    # Apply SMOTE for resampling the training data\n",
    "    X_train_flat = X_train.reshape(X_train.shape[0], -1)  # Flatten for SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_flat, y_train)\n",
    "    X_train_resampled = X_train_resampled.reshape(X_train_resampled.shape[0], 1, X_train.shape[2])  # Reshape back for LSTM\n",
    "\n",
    "    model = create_model((X_train_resampled.shape[1], X_train_resampled.shape[2]))  # (time_steps, features)\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "    # Train the model\n",
    "    class_weights = {0: 1.5, 1: 1.0}  # Increase weight for the minority class\n",
    "    history = model.fit(X_train_resampled, y_train_resampled, \n",
    "                        epochs=50, \n",
    "                        batch_size=32, \n",
    "                        validation_data=(X_test, y_test), \n",
    "                        callbacks=[early_stopping], \n",
    "                        class_weight=class_weights, \n",
    "                        verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")  # Threshold at 0.5 for binary classification\n",
    "    metrics['accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    metrics['precision'].append(precision_score(y_test, y_pred, zero_division=1))\n",
    "    metrics['recall'].append(recall_score(y_test, y_pred, zero_division=1))\n",
    "    metrics['f1'].append(f1_score(y_test, y_pred, zero_division=1))\n",
    "    metrics['confusion_matrices'].append(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print results\n",
    "for key in metrics:\n",
    "    if key != 'confusion_matrices':\n",
    "        print(f\"{key.capitalize()} - Mean: {np.mean(metrics[key]):.2f}, Std: {np.std(metrics[key]):.2f}\")\n",
    "    else:\n",
    "        for i, cm in enumerate(metrics['confusion_matrices']):\n",
    "            print(f\"Confusion Matrix for fold {i + 1}:\\n{cm}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels, return_counts=True)[1], np.unique(y_train_resampled, return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search: hyperparameters\n",
    "learning rate, dropout rate, and LSTM layer sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, make_scorer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# Define the model function for grid search\n",
    "def create_model(lstm_units=32, dropout_rate=0.2, learning_rate=0.001, l2_reg=0.001):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First LSTM layer with regularization\n",
    "    model.add(LSTM(lstm_units, input_shape=(X_reshaped.shape[1], X_reshaped.shape[2]),\n",
    "                   return_sequences=True, kernel_regularizer=l2(l2_reg)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Second LSTM layer with regularization\n",
    "    model.add(LSTM(lstm_units // 2, kernel_regularizer=l2(l2_reg)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Dense output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap the model in KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Define the parameter grid with more diverse LSTM layer sizes and L2 regularization\n",
    "param_grid = {\n",
    "    'lstm_units': [128],          # Different LSTM layer sizes\n",
    "    'dropout_rate': [0.2],      # Different dropout rates\n",
    "    'learning_rate': [0.0001],  # Different learning rates\n",
    "    'l2_reg': [0.001]               # L2 regularization values\n",
    "}\n",
    "\n",
    "# Initialize Stratified K-Fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Use F1-score as the scoring metric\n",
    "scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scorer, cv=kf, verbose=2)\n",
    "\n",
    "# Perform the grid search\n",
    "grid_result = grid_search.fit(X_reshaped, labels)\n",
    "\n",
    "# Output the best parameters and best score\n",
    "print(\"Best parameters found: \", grid_result.best_params_)\n",
    "print(\"Best score: \", grid_result.best_score_)\n",
    "\n",
    "# Evaluate with confusion matrix\n",
    "best_model = grid_result.best_estimator_.model\n",
    "y_pred = (best_model.predict(X_reshaped) > 0.5).astype(\"int32\")\n",
    "conf_matrix = confusion_matrix(labels, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters found:  {'dropout_rate': 0.2, 'learning_rate': 0.001, 'lstm_units': 32}\n",
    "# {'dropout_rate': 0.2, 'l2_reg': 0.001, 'learning_rate': 0.0001, 'lstm_units': 128}\n",
    "# Best score:  0.7191735711731744"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Grid Search Results:\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print(f\"Mean: {mean:.4f} (+/- {std:.4f}) with parameters: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine modulation start features\n",
    "print(psds_bandPower_mod_start.shape)\n",
    "\n",
    "# Combine normal walking features\n",
    "print(psds_bandPower_normal_walking.shape)\n",
    "\n",
    "# Combine all samples\n",
    "print(combined_psds_bandPower.shape)\n",
    "\n",
    "# Generate labels\n",
    "# labels = np.concatenate((np.ones(psds_bandPower_mod_start.shape[0]), np.zeros(psds_bandPower_normal_walking.shape[0])), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternativly do not flatten across the channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psds_bandPower_mod_start = np.concatenate((psds_mod_start,\n",
    "                                           band_power_mod_start), axis=2)\n",
    "\n",
    "psds_bandPower_normal_walking = np.concatenate((psds_normal_walking, \n",
    "                                                band_power_normal_walking), axis=2)\n",
    "\n",
    "combined_psds_bandPower = np.concatenate((psds_bandPower_mod_start,\n",
    "                                          psds_bandPower_normal_walking), axis=0)\n",
    "\n",
    "# Generate labels\n",
    "labels = np.concatenate((np.ones(psds_bandPower_mod_start.shape[0]),\n",
    "                         np.zeros(psds_bandPower_normal_walking.shape[0])), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Reshape the data for LSTM\n",
    "X_reshaped = combined_psds_bandPower.reshape((combined_psds_bandPower.shape[0], \n",
    "                                               combined_psds_bandPower.shape[1], \n",
    "                                               combined_psds_bandPower.shape[2]))\n",
    "\n",
    "# Check the shape after reshaping\n",
    "print(\"X_reshaped shape:\", X_reshaped.shape)  # Expected: (757, 6, 123)\n",
    "\n",
    "# Reshape data to 2D for scaling (samples, features)\n",
    "X_reshaped_2d = X_reshaped.reshape(-1, X_reshaped.shape[-1])\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_reshaped_2d)\n",
    "\n",
    "# Reshape back to 3D\n",
    "X_scaled = X_scaled.reshape(X_reshaped.shape)\n",
    "\n",
    "print(\"X_scaled shape:\", X_scaled.shape)  # Expected: (757, 6, 123)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gait_modulation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
