{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "from gait_modulation import FeatureExtractor, DataProcessor\n",
    "from gait_modulation.utils.utils import split_data, load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed/all_lfp_data.pkl', 'rb') as f:\n",
    "    all_lfp_data = pickle.load(f)\n",
    "    \n",
    "with open('gait_modulation/configs/data_preprocessing.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Time domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 1: Time domain representation of continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 6, 38213)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad or truncate\n",
    "# all_lfp_data should be a list of arrays, each of shape (n_channels, time)\n",
    "all_lfp_uniform_size = DataProcessor.pad_or_truncate(all_lfp_data, config)\n",
    "all_lfp_uniform_size.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('processed/features/time_continuous_uniform-feat.npz',\n",
    "         times_uniform=all_lfp_uniform_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # plt.plot(processed_trials[0][0])\n",
    "# # plt.plot(processed_trials[0][1])\n",
    "# # plt.plot(processed_trials[0][2])\n",
    "# # plt.plot(processed_trials[0][3])\n",
    "# plt.plot(processed_trials[2][4])\n",
    "# # plt.plot(processed_trials[0][5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 2: Time domain representation of continuous data - combine channels * times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 229278)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_trials = all_lfp_uniform_size.shape[0]\n",
    "n_channels = all_lfp_uniform_size.shape[1]\n",
    "n_samples = all_lfp_uniform_size.shape[2]\n",
    "\n",
    "lfp_data_combined_ch_time = all_lfp_uniform_size.reshape((\n",
    "    n_trials, n_channels*n_samples))\n",
    "lfp_data_combined_ch_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('processed/features/time_continuous_uniform_combined_ch_time-feat.npz',\n",
    "         lfp_data_combined_ch_time=lfp_data_combined_ch_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features 3: Summary Statistics on continuous data in the time domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_domain_stats_feat = {\n",
    "    'trials_stat': {\n",
    "        'mean': np.mean(all_lfp_uniform_size, axis=0),\n",
    "        'std': np.std(all_lfp_uniform_size, axis=0),\n",
    "        'median': np.median(all_lfp_uniform_size, axis=0)\n",
    "    },\n",
    "    'channels_stat': {\n",
    "        'mean': np.mean(all_lfp_uniform_size, axis=1),\n",
    "        'std': np.std(all_lfp_uniform_size, axis=1),\n",
    "        'median': np.median(all_lfp_uniform_size, axis=1)\n",
    "    },\n",
    "    'times_stat': {\n",
    "        'mean': np.mean(all_lfp_uniform_size, axis=2),\n",
    "        'std': np.std(all_lfp_uniform_size, axis=2),\n",
    "        'median': np.median(all_lfp_uniform_size, axis=2)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('processed/features/time_continuous_stats-feat.npz', \n",
    "         time_domain_stats_feat=time_domain_stats_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features 4: Summary Statistics on fixed windows in the time domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean features shape: (16, 6, 763)\n",
      "std features shape: (16, 6, 763)\n",
      "median features shape: (16, 6, 763)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16, 6, 38213)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_windowed_stat_feat = FeatureExtractor.extract_windowed_stat_features(\n",
    "    all_lfp_uniform_size,\n",
    "    methods=['mean', 'std', 'median'],\n",
    "    window_size=100, step_size=50, verbose=False)\n",
    "\n",
    "# Check the shape of each feature in the dictionary\n",
    "for method, features in time_windowed_stat_feat.items():\n",
    "    print(f\"{method} features shape:\", features.shape)\n",
    "\n",
    "np.savez('processed/features/time_windowed_stat-feat.npz', \n",
    "         time_windowed_stat_feat=time_windowed_stat_feat)\n",
    "all_lfp_uniform_size.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 5: Time domain representation of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/gait_modulation/processed/lfp_-3.0tmin_5gap-epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =   -3000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "893 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "epochs = mne.read_epochs('processed/lfp_-3.0tmin_5gap-epo.fif')\n",
    "time_epoched = epochs.get_data(copy=False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('processed/features/time_epoched-feat.npz', \n",
    "         time_epoched=time_epoched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 6: Time domain representation of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avergave by: epochs, feature: mean, shape: (6, 751)\n",
      "Avergave by: epochs, feature: std, shape: (6, 751)\n",
      "Avergave by: epochs, feature: median, shape: (6, 751)\n",
      "Avergave by: channels, feature: mean, shape: (893, 751)\n",
      "Avergave by: channels, feature: std, shape: (893, 751)\n",
      "Avergave by: channels, feature: median, shape: (893, 751)\n",
      "Avergave by: times, feature: mean, shape: (893, 6)\n",
      "Avergave by: times, feature: std, shape: (893, 6)\n",
      "Avergave by: times, feature: median, shape: (893, 6)\n"
     ]
    }
   ],
   "source": [
    "time_epoched_stat_feat = FeatureExtractor.extract_epoched_stat_features(\n",
    "    epochs=epochs, methods=['mean', 'std', 'median'])\n",
    "\n",
    "np.savez('processed/features/time_epoched_stat-feat.npz', \n",
    "         time_epoched_stat_feat=time_epoched_stat_feat)\n",
    "\n",
    "for agg_method, features in time_epoched_stat_feat.items():\n",
    "    for feat_name, feat_values in features.items():\n",
    "        print(f\"Avergave by: {agg_method}, feature: {feat_name}, shape: {feat_values.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Frequency domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 1: Frequency domain representation of epoched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_bands = {\n",
    "    'delta': (0.1, 3),\n",
    "    'theta': (4, 7),\n",
    "    'alpha': (8, 12),\n",
    "    'low_beta': (12, 16),\n",
    "    'middle_beta': (16, 20),\n",
    "    'high_beta': (20, 30),\n",
    "    'gamma': (30, 100),\n",
    "    'high_gamma': (100, 125)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 3.004 (s)\n",
      "(375,)\n",
      "(893, 6, 375)\n",
      "(893, 6, 8)\n"
     ]
    }
   ],
   "source": [
    "# Exrtact spectral features for both classes at once\n",
    "psds, freqs, band_power = FeatureExtractor.extract_psd_and_band_power(\n",
    "    epochs,\n",
    "    freq_bands,\n",
    "    fmin=min([f[0] for f in freq_bands.values()]),\n",
    "    fmax=max([f[1] for f in freq_bands.values()])\n",
    ")\n",
    "np.savez_compressed('processed/features/psd_bandPower-feat.npz', \n",
    "                    psds=psds, \n",
    "                    band_power=band_power)\n",
    "\n",
    "print(freqs.shape)\n",
    "print(psds.shape)  \n",
    "print(band_power.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mod_start features\n",
    "# spectral_feat_mod_start = FeatureExtractor.extract_psd_and_band_power(\n",
    "#     epochs['mod_start'],\n",
    "#     freq_bands,\n",
    "#     fmin=min([f[0] for f in freq_bands.values()]),\n",
    "#     fmax=max([f[1] for f in freq_bands.values()])\n",
    "# )\n",
    "# psds_mod_start, freqs_mod_start, band_power_mod_start = spectral_feat_mod_start\n",
    "\n",
    "# np.savez_compressed('processed/features/spectral_feat_mod_start.npz', \n",
    "#                     psds_mod_start=psds_mod_start, \n",
    "#                     band_power_mod_start=band_power_mod_start)\n",
    "\n",
    "# print(freqs_mod_start.shape)\n",
    "# print(psds_mod_start.shape)  \n",
    "# print(band_power_mod_start.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normal_walking features\n",
    "# spectral_feat_normal_walking = FeatureExtractor.extract_psd_and_band_power(\n",
    "#     epochs['normal_walking'],\n",
    "#     freq_bands,\n",
    "#     fmin=min([f[0] for f in freq_bands.values()]),\n",
    "#     fmax=max([f[1] for f in freq_bands.values()])\n",
    "# )\n",
    "\n",
    "# psds_normal_walking, freqs_normal_walking, band_power_normal_walking = spectral_feat_normal_walking\n",
    "\n",
    "# np.savez_compressed('processed/features/spectral_feat_normal_walking.npz', \n",
    "#                     psds_normal_walking=psds_normal_walking, \n",
    "#                     band_power_normal_walking=band_power_normal_walking)\n",
    "\n",
    "# print(freqs_normal_walking.shape)\n",
    "# print(psds_normal_walking.shape)  \n",
    "# print(band_power_normal_walking.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psds_bandPower_mod_start = np.concatenate((psds_mod_start,\n",
    "#                                            band_power_mod_start), axis=2)\n",
    "\n",
    "# psds_bandPower_normal_walking = np.concatenate((psds_normal_walking, \n",
    "#                                                 band_power_normal_walking), axis=2)\n",
    "\n",
    "# psds_bandPower_both_classes = np.concatenate((psds_bandPower_mod_start,\n",
    "#                                               psds_bandPower_normal_walking), axis=0)\n",
    "# # Generate labels\n",
    "# labels = np.concatenate((np.ones(psds_bandPower_mod_start.shape[0]),\n",
    "#                          -np.ones(psds_bandPower_normal_walking.shape[0])), axis=0)\n",
    "\n",
    "# print(psds_mod_start.shape, band_power_mod_start.shape, psds_bandPower_mod_start.shape)\n",
    "# print(psds_normal_walking.shape, band_power_normal_walking.shape, psds_bandPower_normal_walking.shape)\n",
    "\n",
    "# print(psds_bandPower_both_classes.shape, labels.shape)\n",
    "# psds_bandPower_both_classes.reshape(psds_bandPower_both_classes.shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine modulation start features\n",
    "# psds_bandPower_mod_start2 = np.concatenate((\n",
    "#     psds_mod_start.reshape(psds_mod_start.shape[0], -1),\n",
    "#     band_power_mod_start.reshape(band_power_mod_start.shape[0], -1)), axis=1)\n",
    "\n",
    "# # Combine normal walking features\n",
    "# psds_bandPower_normal_walking2 = np.concatenate((\n",
    "#     psds_normal_walking.reshape(psds_normal_walking.shape[0], -1),\n",
    "#     band_power_normal_walking.reshape(band_power_normal_walking.shape[0], -1)), axis=1)\n",
    "\n",
    "# combined_psds_bandPower2 = np.concatenate((psds_bandPower_mod_start2,\n",
    "#                                           psds_bandPower_normal_walking2), axis=0)\n",
    "# # Generate labels\n",
    "# labels2 = np.concatenate((np.ones(psds_bandPower_mod_start2.shape[0]),\n",
    "#                          np.zeros(psds_bandPower_normal_walking2.shape[0])), axis=0)\n",
    "\n",
    "\n",
    "# print(psds_mod_start.shape, band_power_mod_start.shape, psds_bandPower_mod_start2.shape)\n",
    "# print(psds_normal_walking.shape, band_power_normal_walking.shape, psds_bandPower_normal_walking2.shape)\n",
    "\n",
    "# print(combined_psds_bandPower2.shape, labels2.shape)\n",
    "# combined_psds_bandPower2.reshape(combined_psds_bandPower2.shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = psds_bandPower_both_classes.reshape(psds_bandPower_both_classes.shape[0], -1)\n",
    "# y = labels\n",
    "# splits = split_data(X, y, n_splits=5)\n",
    "\n",
    "# print(X.shape, y.shape, '\\n')\n",
    "# for i, (X_train, X_test, y_train, y_test) in enumerate(splits):\n",
    "#     print(f\"Fold {i+1}:\")\n",
    "#     print(\"X_train shape:\", X_train.shape)\n",
    "#     print(\"X_test shape:\", X_test.shape)\n",
    "#     print(\"y_train shape:\", y_train.shape)\n",
    "#     print(\"y_test shape:\", y_test.shape)\n",
    "#     print(\"---------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
