{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/orabe/gait_modulation.git"
      ],
      "metadata": {
        "id": "NmwDy9iXihMC",
        "outputId": "23de4b73-e126-4a36-fd91-0bf6c7da3bba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gait_modulation'...\n",
            "remote: Enumerating objects: 605, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 605 (delta 5), reused 15 (delta 5), pack-reused 577 (from 2)\u001b[K\n",
            "Receiving objects: 100% (605/605), 251.48 MiB | 23.31 MiB/s, done.\n",
            "Resolving deltas: 100% (284/284), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd gait_modulation"
      ],
      "metadata": {
        "id": "fLDhw7L9iocU",
        "outputId": "0dcd88a1-f53a-4882-d39b-53cada53a5bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gait_modulation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "cKhSzLpGiz4o",
        "outputId": "6f717e1b-2e3b-4fdf-8664-fc359136490e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CITATION.cff\t examples\t\t\t LICENSE   pyproject.toml  requirements.txt  source\n",
            "CONTRIBUTING.md  gait_modulation\t\t make.bat  README.md\t   results\n",
            "environment.yml  gait_modulation.code-workspace  Makefile  README.rst\t   _setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gait_modulation"
      ],
      "metadata": {
        "id": "fY6UIk1VjMfT",
        "outputId": "f9451b6d-60e0-4c0d-c461-fb8d0c0c24ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gait_modulation in /usr/local/lib/python3.11/dist-packages (0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from gait_modulation) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from gait_modulation) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from gait_modulation) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from gait_modulation) (0.13.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from gait_modulation) (1.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gait_modulation) (4.67.1)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.11/dist-packages (from gait_modulation) (8.1.3)\n",
            "Requirement already satisfied: sphinx_rtd_theme in /usr/local/lib/python3.11/dist-packages (from gait_modulation) (3.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-napoleon in /usr/local/lib/python3.11/dist-packages (from gait_modulation) (0.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gait_modulation) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gait_modulation) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gait_modulation) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gait_modulation) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gait_modulation) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gait_modulation) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gait_modulation) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gait_modulation) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->gait_modulation) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->gait_modulation) (2025.1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from sphinx->gait_modulation) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx->gait_modulation) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx->gait_modulation) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from sphinx->gait_modulation) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx->gait_modulation) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.11/dist-packages (from sphinx->gait_modulation) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.11/dist-packages (from sphinx->gait_modulation) (3.1.6)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.11/dist-packages (from sphinx->gait_modulation) (2.18.0)\n",
            "Requirement already satisfied: docutils<0.22,>=0.20 in /usr/local/lib/python3.11/dist-packages (from sphinx->gait_modulation) (0.21.2)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.11/dist-packages (from sphinx->gait_modulation) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.11/dist-packages (from sphinx->gait_modulation) (2.17.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.11/dist-packages (from sphinx->gait_modulation) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.11/dist-packages (from sphinx->gait_modulation) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.30.0 in /usr/local/lib/python3.11/dist-packages (from sphinx->gait_modulation) (2.32.3)\n",
            "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /usr/local/lib/python3.11/dist-packages (from sphinx_rtd_theme->gait_modulation) (4.1)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.11/dist-packages (from sphinxcontrib-napoleon->gait_modulation) (1.17.0)\n",
            "Requirement already satisfied: pockets>=0.3 in /usr/local/lib/python3.11/dist-packages (from sphinxcontrib-napoleon->gait_modulation) (0.9.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1->sphinx->gait_modulation) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx->gait_modulation) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx->gait_modulation) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx->gait_modulation) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx->gait_modulation) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r gait_modulation/requirements.txt"
      ],
      "metadata": {
        "id": "LX-mJgrvj0ax",
        "outputId": "f98fe80e-55c3-465a-8193-3addf8c010e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting antropy==0.1.9 (from -r gait_modulation/requirements.txt (line 2))\n",
            "  Downloading antropy-0.1.9-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting imbalanced_learn==0.12.4 (from -r gait_modulation/requirements.txt (line 3))\n",
            "  Downloading imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting keras==3.9.0 (from -r gait_modulation/requirements.txt (line 4))\n",
            "  Downloading keras-3.9.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting matplotlib==3.8.4 (from -r gait_modulation/requirements.txt (line 5))\n",
            "  Downloading matplotlib-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting mne==1.7.1 (from -r gait_modulation/requirements.txt (line 6))\n",
            "  Downloading mne-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting numpy==1.26.4 (from -r gait_modulation/requirements.txt (line 7))\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==2.2.1 (from -r gait_modulation/requirements.txt (line 8))\n",
            "  Downloading pandas-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: pyyaml==6.0.2 in /usr/local/lib/python3.11/dist-packages (from -r gait_modulation/requirements.txt (line 9)) (6.0.2)\n",
            "Collecting scikit_learn==1.5.1 (from -r gait_modulation/requirements.txt (line 10))\n",
            "  Downloading scikit_learn-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting scipy==1.13.0 (from -r gait_modulation/requirements.txt (line 11))\n",
            "  Downloading scipy-1.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: seaborn==0.13.2 in /usr/local/lib/python3.11/dist-packages (from -r gait_modulation/requirements.txt (line 12)) (0.13.2)\n",
            "Collecting setuptools==69.5.1 (from -r gait_modulation/requirements.txt (line 13))\n",
            "  Downloading setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tqdm==4.66.4 (from -r gait_modulation/requirements.txt (line 14))\n",
            "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydot==3.0.4 in /usr/local/lib/python3.11/dist-packages (from -r gait_modulation/requirements.txt (line 15)) (3.0.4)\n",
            "Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.11/dist-packages (from antropy==0.1.9->-r gait_modulation/requirements.txt (line 2)) (0.60.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced_learn==0.12.4->-r gait_modulation/requirements.txt (line 3)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced_learn==0.12.4->-r gait_modulation/requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras==3.9.0->-r gait_modulation/requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras==3.9.0->-r gait_modulation/requirements.txt (line 4)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras==3.9.0->-r gait_modulation/requirements.txt (line 4)) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras==3.9.0->-r gait_modulation/requirements.txt (line 4)) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras==3.9.0->-r gait_modulation/requirements.txt (line 4)) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras==3.9.0->-r gait_modulation/requirements.txt (line 4)) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras==3.9.0->-r gait_modulation/requirements.txt (line 4)) (24.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.4->-r gait_modulation/requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.4->-r gait_modulation/requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.4->-r gait_modulation/requirements.txt (line 5)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.4->-r gait_modulation/requirements.txt (line 5)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.4->-r gait_modulation/requirements.txt (line 5)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.4->-r gait_modulation/requirements.txt (line 5)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.4->-r gait_modulation/requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne==1.7.1->-r gait_modulation/requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne==1.7.1->-r gait_modulation/requirements.txt (line 6)) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne==1.7.1->-r gait_modulation/requirements.txt (line 6)) (0.4)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne==1.7.1->-r gait_modulation/requirements.txt (line 6)) (1.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.1->-r gait_modulation/requirements.txt (line 8)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.1->-r gait_modulation/requirements.txt (line 8)) (2025.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57->antropy==0.1.9->-r gait_modulation/requirements.txt (line 2)) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne==1.7.1->-r gait_modulation/requirements.txt (line 6)) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne==1.7.1->-r gait_modulation/requirements.txt (line 6)) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.8.4->-r gait_modulation/requirements.txt (line 5)) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne==1.7.1->-r gait_modulation/requirements.txt (line 6)) (3.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras==3.9.0->-r gait_modulation/requirements.txt (line 4)) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras==3.9.0->-r gait_modulation/requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras==3.9.0->-r gait_modulation/requirements.txt (line 4)) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras==3.9.0->-r gait_modulation/requirements.txt (line 4)) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne==1.7.1->-r gait_modulation/requirements.txt (line 6)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne==1.7.1->-r gait_modulation/requirements.txt (line 6)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne==1.7.1->-r gait_modulation/requirements.txt (line 6)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne==1.7.1->-r gait_modulation/requirements.txt (line 6)) (2025.1.31)\n",
            "Downloading antropy-0.1.9-py3-none-any.whl (18 kB)\n",
            "Downloading imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.3/258.3 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-3.9.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mne-1.7.1-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-69.5.1-py3-none-any.whl (894 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m894.6/894.6 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm, setuptools, numpy, scipy, pandas, scikit_learn, matplotlib, keras, mne, imbalanced_learn, antropy\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.1.0\n",
            "    Uninstalling setuptools-75.1.0:\n",
            "      Successfully uninstalled setuptools-75.1.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: scikit_learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: mne\n",
            "    Found existing installation: mne 1.9.0\n",
            "    Uninstalling mne-1.9.0:\n",
            "      Successfully uninstalled mne-1.9.0\n",
            "  Attempting uninstall: imbalanced_learn\n",
            "    Found existing installation: imbalanced-learn 0.13.0\n",
            "    Uninstalling imbalanced-learn-0.13.0:\n",
            "      Successfully uninstalled imbalanced-learn-0.13.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed antropy-0.1.9 imbalanced_learn-0.12.4 keras-3.9.0 matplotlib-3.8.4 mne-1.7.1 numpy-1.26.4 pandas-2.2.1 scikit_learn-1.5.1 scipy-1.13.0 setuptools-69.5.1 tqdm-4.66.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "keras",
                  "matplotlib",
                  "mpl_toolkits",
                  "setuptools"
                ]
              },
              "id": "0350a751ef7f46c491edb56843d04eb0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wevNUAB6idAn",
        "outputId": "e765e6bd-22ff-4ffe-b6f4-658a76b6db0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'antropy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-94f24add98db>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgait_modulation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatureExtractor2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgait_modulation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLSTMClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgait_modulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_pkl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialize_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable_xla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gait_modulation/gait_modulation/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_data_stratified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_lagged_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_continuous_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatureExtractor2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_classification_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLSTMClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCustomGridSearchCV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCustomTrainingLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gait_modulation/gait_modulation/models/feature_extraction.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mantropy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mFeatureExtractor2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'antropy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# %%\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import save_model, load_model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut, cross_val_predict\n",
        "from sklearn.metrics import make_scorer, accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import logging\n",
        "import seaborn as sns\n",
        "from io import StringIO\n",
        "\n",
        "from gait_modulation import FeatureExtractor2\n",
        "from gait_modulation import LSTMClassifier\n",
        "from gait_modulation.utils.utils import load_pkl, initialize_tf, disable_xla\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crSqlBH2idAp"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "def load_data():\n",
        "    \"\"\"Load the preprocessed data from the pickles.\"\"\"\n",
        "    patient_epochs_path = os.path.join(\"results\", \"pickles\", \"patients_epochs.pickle\")\n",
        "    subjects_event_idx_dict_path = os.path.join(\"results\", \"pickles\", \"subjects_event_idx_dict.pickle\")\n",
        "\n",
        "    patient_epochs = load_pkl(patient_epochs_path)\n",
        "    subjects_event_idx_dict = load_pkl(subjects_event_idx_dict_path)\n",
        "\n",
        "    patient_names = np.array(list(patient_epochs.keys()))\n",
        "    print(f\"Loaded data for {len(patient_names)} patients.\")\n",
        "    return patient_epochs, subjects_event_idx_dict, patient_names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKoXtWSAidAp"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "def preprocess_data(patient_epochs, patient_names, sfreq, feature_handling=\"flatten_chs\", mask_vals=(0.0, 2), features_config=None, n_windows_threshold=None):\n",
        "\n",
        "    feature_extractor = FeatureExtractor2(sfreq, features_config)\n",
        "\n",
        "    # X_grouped is a list where each element is (n_windows_per_trial, n_features)\n",
        "    X_grouped, y_grouped, groups = [], [], []\n",
        "    excluded_count = 0\n",
        "\n",
        "    for patient in patient_names:\n",
        "        epochs = patient_epochs[patient]\n",
        "\n",
        "        # Extract trial indices\n",
        "        trial_indices = epochs.events[:, 1]  # Middle column contains trial index\n",
        "        unique_trials = np.unique(trial_indices)\n",
        "        # print(f\"- Patient {patient} has {len(unique_trials)} trials\")\n",
        "\n",
        "        # Extract features and labels\n",
        "        X_patient, y_patient = feature_extractor.extract_features_with_labels(epochs, feature_handling)\n",
        "\n",
        "        # Group windows by trial\n",
        "        for trial in unique_trials:\n",
        "            trial_mask = trial_indices == trial  # Find windows belonging to this trial\n",
        "            n_windows = sum(trial_mask)\n",
        "\n",
        "            if n_windows_threshold is not None and n_windows > n_windows_threshold:\n",
        "                # print(f\"Trial {trial} has {n_windows} windows, excluding...\")\n",
        "                excluded_count += 1\n",
        "                continue\n",
        "\n",
        "            X_grouped.append(X_patient[trial_mask])  # Store all windows of this trial\n",
        "            y_grouped.append(y_patient[trial_mask])  # Store labels for this trial\n",
        "            groups.append(patient)  # Keep track of the patient\n",
        "\n",
        "            # print(f\"Trial {trial} has {n_windows} windows\")\n",
        "    print(\"Number of excluded trials:\", excluded_count)\n",
        "\n",
        "    X_padded = pad_sequences(X_grouped, dtype='float32', padding='post', value=mask_vals[0])\n",
        "    y_padded = pad_sequences(y_grouped, dtype='int32', padding='post', value=mask_vals[1])\n",
        "\n",
        "    print(\"Padded X shape:\", X_padded.shape)\n",
        "    print(\"Padded y shape:\", y_padded.shape)\n",
        "\n",
        "    assert not np.any(np.isnan(X_padded)), \"X_grouped contains NaNs\"\n",
        "    assert not np.any(np.isnan(y_padded)), \"y_grouped contains NaNs\"\n",
        "    assert X_padded.shape[0] == y_padded.shape[0] == len(groups), \"X, y, and groups should have the same number of trials\"\n",
        "    assert X_padded.shape[1] == y_padded.shape[1], \"X and y should have the same number of windows\"\n",
        "\n",
        "    padded_data_path = os.path.join(\"results\", \"padded_data.npz\")\n",
        "    np.savez(padded_data_path, X_padded=X_padded, y_padded=y_padded)\n",
        "    print(f\"Padded data saved at {padded_data_path}.\")\n",
        "\n",
        "    return X_padded, y_padded, groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGcPJrIEidAq"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "def setup_logging():\n",
        "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    model_dir = os.path.join(\"logs\", \"lstm\", \"models\", f\"logs_run_{timestamp}\")\n",
        "    log_dir = os.path.join(model_dir, \"logs\")\n",
        "    history_dir = os.path.join(model_dir, 'training_history')\n",
        "\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "    os.makedirs(history_dir, exist_ok=True)\n",
        "\n",
        "    log_stream = StringIO()\n",
        "    logging.basicConfig(\n",
        "        stream=log_stream,\n",
        "        level=logging.INFO,\n",
        "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
        "    )\n",
        "\n",
        "    console_handler = logging.StreamHandler()\n",
        "    console_handler.setLevel(logging.INFO)\n",
        "    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "    console_handler.setFormatter(formatter)\n",
        "    logging.getLogger().addHandler(console_handler)\n",
        "\n",
        "    logging.info(\"Logging setup complete. Starting training process.\")\n",
        "\n",
        "    return model_dir, history_dir, log_stream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8Fh_1Z9idAq"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "def build_pipeline(input_shape, n_windows, mask_vals):\n",
        "    models = {\n",
        "        'lstm': LSTMClassifier(input_shape=input_shape)\n",
        "    }\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', 'passthrough'),\n",
        "        ('classifier', models['lstm'])\n",
        "    ])\n",
        "\n",
        "    param_grid = [\n",
        "        {\n",
        "            'classifier__hidden_dims': [[32, 32]],\n",
        "            'classifier__activations': [['tanh', 'relu']],\n",
        "            'classifier__recurrent_activations': [['sigmoid', 'hard_sigmoid']],\n",
        "            'classifier__dropout': [0.2],\n",
        "            'classifier__dense_units': [n_windows],\n",
        "            'classifier__dense_activation': ['sigmoid'],\n",
        "            'classifier__optimizer': ['adam'],\n",
        "            'classifier__lr': [0.001],\n",
        "            'classifier__patience': [10],\n",
        "            'classifier__epochs': [2],\n",
        "            'classifier__batch_size': [128],\n",
        "            'classifier__threshold': [0.5],\n",
        "            'classifier__loss': ['binary_crossentropy'],\n",
        "            'classifier__mask_vals': [mask_vals],\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    scoring = {\n",
        "        'accuracy': make_scorer(LSTMClassifier.masked_accuracy_score),\n",
        "        'f1': make_scorer(LSTMClassifier.masked_f1_score),\n",
        "    }\n",
        "\n",
        "    if any(hasattr(model, \"predict_proba\") for model in models.values()):\n",
        "        scoring['roc_auc'] = make_scorer(LSTMClassifier.masked_roc_auc_score,\n",
        "                                        # needs_proba=True,\n",
        "                                        response_method='predict_proba',\n",
        "                                        multi_class='ovr')\n",
        "\n",
        "    return pipeline, param_grid, scoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6sdSfc9idAq"
      },
      "outputs": [],
      "source": [
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "initialize_tf()\n",
        "\n",
        "patient_epochs, subjects_event_idx_dict, patient_names = load_data()\n",
        "\n",
        "# Slice patients for testing\n",
        "patient_names = patient_names[:5]\n",
        "patient_epochs = {k: patient_epochs[k] for k in patient_names}\n",
        "subjects_event_idx_dict = {k: subjects_event_idx_dict[k] for k in patient_names}\n",
        "\n",
        "sfreq = patient_epochs[patient_names[0]].info['sfreq']\n",
        "feature_handling = \"flatten_chs\"\n",
        "mask_vals = (0.0, 2)\n",
        "\n",
        "config_path = os.path.join(\"configs\", \"features_config.json\")\n",
        "if os.path.exists(config_path):\n",
        "    with open(config_path, 'r') as f:\n",
        "        features_config = json.load(f)\n",
        "    print(f\"Loaded features configuration from {config_path}.\")\n",
        "else:\n",
        "    features_config = None\n",
        "    print(f\"No features configuration file found at {config_path}. Using default configuration.\")\n",
        "\n",
        "features_config = None\n",
        "if features_config is None:\n",
        "    features_config = {\n",
        "        'time_features': {\n",
        "            # 'mean': True,\n",
        "            # 'std': True,\n",
        "            # 'median': True,\n",
        "            # 'skew': True,\n",
        "            # 'kurtosis': True,\n",
        "            # 'rms': True\n",
        "                # peak_to_peak = np.ptp(lfp_data, axis=2)\n",
        "        },\n",
        "        'freq_features': {\n",
        "            'psd_raw': True,\n",
        "                # psd_vals = np.abs(np.fft.rfft(lfp_data, axis=2))\n",
        "            # 'psd_band_mean': True, band power!\n",
        "            # 'psd_band_std': True,\n",
        "            # 'spectral_entropy': True\n",
        "        },\n",
        "        # 'wavelet_features': {\n",
        "        #     'energy': False\n",
        "        # },\n",
        "        # 'nonlinear_features': {\n",
        "        #     'sample_entropy': True,\n",
        "        #     'hurst_exponent': False\n",
        "        # }\n",
        "    }\n",
        "\n",
        "X_padded, y_padded, groups = preprocess_data(patient_epochs, patient_names, sfreq, feature_handling, mask_vals, features_config)\n",
        "\n",
        "n_features = X_padded.shape[2]\n",
        "n_windows = X_padded.shape[1]\n",
        "input_shape = (None, n_features)\n",
        "\n",
        "model_dir, history_dir, log_stream = setup_logging()\n",
        "pipeline, param_grid, scoring = build_pipeline(input_shape, n_windows, mask_vals)\n",
        "\n",
        "logo = LeaveOneGroupOut()\n",
        "n_splits = logo.get_n_splits(X_padded, y_padded, groups)\n",
        "print(f\"Total fits: {n_splits * len(param_grid)}\")\n",
        "print(f\"Number of splits: {n_splits}, Number of parameters: {len(param_grid)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hs94jAnXidAq"
      },
      "outputs": [],
      "source": [
        "logging.info(\"Starting Grid Search...\")\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid=param_grid,\n",
        "    cv=logo,\n",
        "    scoring=scoring,\n",
        "    refit='f1' if 'f1' in scoring else 'accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=3,\n",
        ")\n",
        "\n",
        "grid_search.fit(X_padded, y_padded, groups=groups)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFFD-DaGidAr"
      },
      "outputs": [],
      "source": [
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
        "logging.info(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "logging.info(f\"Best Score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "best_model = grid_search.best_estimator_.named_steps['classifier'].model\n",
        "model_summary_path = os.path.join(model_dir, \"best_model_summary.txt\")\n",
        "with open(model_summary_path, 'w') as f:\n",
        "    best_model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
        "print(best_model.summary())\n",
        "print(f\"Best model summary saved at {model_summary_path}.\")\n",
        "\n",
        "best_model_path = os.path.join(model_dir, \"best_lstm_model.h5\")\n",
        "keras_model_path = os.path.join(model_dir, 'best_lstm_model.keras')\n",
        "best_model.save(best_model_path)\n",
        "save_model(best_model, keras_model_path)\n",
        "print(f\"Best LSTM model saved at {best_model_path}.\")\n",
        "logging.info(f\"Best LSTM model saved at {best_model_path}.\")\n",
        "\n",
        "best_params_path = os.path.join(model_dir, 'best_params.json')\n",
        "cv_results_path = os.path.join(model_dir, 'cv_results.csv')\n",
        "evaluation_metrics_path = os.path.join(model_dir, 'evaluation_metrics.json')\n",
        "\n",
        "for fold, history in enumerate(grid_search.best_estimator_.named_steps['classifier'].history_):\n",
        "    history_path = os.path.join(history_dir, f'training_history_fold_{fold + 1}.json')\n",
        "    with open(history_path, 'w') as f:\n",
        "        json.dump(history, f)\n",
        "    print(f\"Training history for fold {fold + 1} saved at {history_path}\")\n",
        "\n",
        "with open(best_params_path, 'w') as f:\n",
        "    json.dump(grid_search.best_params_, f)\n",
        "print(f\"Best parameters saved at {best_params_path}\")\n",
        "\n",
        "results_df = pd.DataFrame(grid_search.cv_results_)\n",
        "results_df.to_csv(cv_results_path, index=False)\n",
        "print(f\"Cross-validation results saved at {cv_results_path}\")\n",
        "\n",
        "plot_model(best_model, to_file=os.path.join(model_dir, 'model_architecture.png'), show_shapes=True)\n",
        "print(f\"Model architecture plot saved at {os.path.join(model_dir, 'model_architecture.png')}.\")\n",
        "\n",
        "log_file_path = os.path.join(model_dir, 'training.log')\n",
        "with open(log_file_path, 'w') as f:\n",
        "    f.write(log_stream.getvalue())\n",
        "print(f\"Training logs saved at {log_file_path}.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}