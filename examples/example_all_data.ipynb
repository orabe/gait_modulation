{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import mne\n",
    "\n",
    "from gait_modulation.file_reader import MatFileReader\n",
    "from gait_modulation.data_processor import DataProcessor\n",
    "from gait_modulation.viz import Visualise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle multiple patients with nested directories.\n",
    "root_directory = '/Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/Chiara/organized_data'\n",
    "mat_reader = MatFileReader(root_directory, max_workers=1)  #  adjust the number of workers for parallelism\n",
    "\n",
    "# Read all data from nested folders of multiple patients and sessions\n",
    "all_data = mat_reader.read_data()\n",
    "n_sessions = len(all_data)\n",
    "\n",
    "print(f\"Number of sessions: {n_sessions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 6 PCA components\n",
      "Not setting metadata\n",
      "66 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 66 events and 501 original time points ...\n",
      "1 bad epochs dropped\n",
      "Epochs info: <Epochs |  65 events (all good), -2 – 0 s, baseline off, ~1.5 MB, data loaded,\n",
      " 'mod_start': 6\n",
      " 'normal_walking': 59>\n",
      "Number of epochs: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as plots/1_hist.png\n",
      "Plot saved as plots/1_event_classes.png\n",
      "Number of samples removed: 2282\n",
      "Number of seconds removed: 9.13 seconds\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=44688\n",
      "    Range : 0 ... 44687 =      0.000 ...   178.748 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 50 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 50.00 Hz\n",
      "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
      "- Filter length: 825 samples (3.300 s)\n",
      "\n",
      "['LFP_L03', 'LFP_L13', 'LFP_L02', 'LFP_R03', 'LFP_R13', 'LFP_R02']\n",
      "Fitting ICA to data using 6 channels (please be patient, this may take a while)\n",
      "Selecting by number: 6 components\n",
      "Fitting ICA took 0.0s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (6 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 6 PCA components\n",
      "Not setting metadata\n",
      "27 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 27 events and 501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Epochs info: <Epochs |  27 events (all good), -2 – 0 s, baseline off, ~644 kB, data loaded,\n",
      " 'mod_start': 15\n",
      " 'normal_walking': 12>\n",
      "Number of epochs: 27\n",
      "Plot saved as plots/2_hist.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as plots/2_event_classes.png\n",
      "Number of samples removed: 7049\n",
      "Number of seconds removed: 28.20 seconds\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=38563\n",
      "    Range : 0 ... 38562 =      0.000 ...   154.248 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 50 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 50.00 Hz\n",
      "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
      "- Filter length: 825 samples (3.300 s)\n",
      "\n",
      "['LFP_L03', 'LFP_L13', 'LFP_L02', 'LFP_R03', 'LFP_R13', 'LFP_R02']\n",
      "Fitting ICA to data using 6 channels (please be patient, this may take a while)\n",
      "Selecting by number: 6 components\n",
      "Fitting ICA took 0.0s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (6 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 6 PCA components\n",
      "Not setting metadata\n",
      "28 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 28 events and 501 original time points ...\n",
      "1 bad epochs dropped\n",
      "Epochs info: <Epochs |  27 events (all good), -2 – 0 s, baseline off, ~644 kB, data loaded,\n",
      " 'mod_start': 11\n",
      " 'normal_walking': 16>\n",
      "Number of epochs: 27\n",
      "Plot saved as plots/3_hist.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as plots/3_event_classes.png\n",
      "Number of samples removed: 1950\n",
      "Number of seconds removed: 7.80 seconds\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=43437\n",
      "    Range : 0 ... 43436 =      0.000 ...   173.744 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 50 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 50.00 Hz\n",
      "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
      "- Filter length: 825 samples (3.300 s)\n",
      "\n",
      "['LFP_L03', 'LFP_L13', 'LFP_L02', 'LFP_R03', 'LFP_R13', 'LFP_R02']\n",
      "Fitting ICA to data using 6 channels (please be patient, this may take a while)\n",
      "Selecting by number: 6 components\n",
      "Fitting ICA took 0.0s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (6 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 6 PCA components\n",
      "Not setting metadata\n",
      "64 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 64 events and 501 original time points ...\n",
      "8 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store epochs and events\n",
    "train_all_epochs = []\n",
    "train_all_events = []\n",
    "\n",
    "test_all_epochs = []\n",
    "test_all_events = []\n",
    "\n",
    "test_session_idx = [2, 3, 4]\n",
    "\n",
    "for s in range(n_sessions):\n",
    "    # Access specific sessions for a patient\n",
    "    session = all_data[s]\n",
    "\n",
    "    # Extract events and lfp data of the subject/session\n",
    "    lfp_data = session['data_LFP']\n",
    "    lfp_data *= 1e-6  # Convert microvolts to volts\n",
    "    lfp_metadata = DataProcessor.np_to_dict(session['hdr_LFP'])\n",
    "    events_KIN = DataProcessor.np_to_dict(session['events_KIN'])\n",
    "\n",
    "    # Load parameters\n",
    "    lfp_sfreq = lfp_metadata['Fs'].item()\n",
    "    lfp_ch_names = DataProcessor.rename_lfp_channels(lfp_metadata['labels'])\n",
    "    lfp_n_channels = lfp_metadata['NumberOfChannels'].item()\n",
    "\n",
    "    # Prepare for mne data structure\n",
    "    info = mne.create_info(ch_names=lfp_ch_names[0:6], sfreq=lfp_sfreq, ch_types='dbs')\n",
    "    # lfp_raw = mne.io.RawArray(lfp_data, info)\n",
    "\n",
    "    # Handle events\n",
    "    ori_events, ori_event_dict = DataProcessor.create_events_array(events_KIN, lfp_sfreq)\n",
    "\n",
    "    # Trim the data and adjust the event onsets accordingly\n",
    "    lfp_data, events = DataProcessor.trim_data(lfp_data, ori_events, lfp_sfreq)\n",
    "\n",
    "    # Update raw data after trimming\n",
    "    lfp_raw = mne.io.RawArray(lfp_data, info)\n",
    "\n",
    "    # Select one event to work with: mod_start\n",
    "    event_of_interest = 'mod_start'\n",
    "    events_mod_start = ori_events[ori_events[:, 2] == ori_event_dict[event_of_interest]]\n",
    "\n",
    "    # Rename Gait Modulation Events\n",
    "    mod_start_event_id = 1\n",
    "    events_mod_start[:, 2] = mod_start_event_id\n",
    "\n",
    "    # Define parameters\n",
    "    epoch_tmin = -2.0\n",
    "    epoch_tmax = 0.0\n",
    "    epoch_duration_length = epoch_tmax - epoch_tmin\n",
    "    epoch_sample_length = int(epoch_duration_length * lfp_sfreq)\n",
    "    gap_duration = 10  # At least 10 seconds away from modulation events\n",
    "    gap_sample_length = int(gap_duration * lfp_sfreq)\n",
    "    lfp_duration = lfp_data.shape[1] / lfp_sfreq\n",
    "    n_samples = int(lfp_duration * lfp_sfreq)\n",
    "\n",
    "    # Define normal walking events\n",
    "    normal_walking_event_id = -1\n",
    "    normal_walking_events = DataProcessor.define_normal_walking_events(\n",
    "        normal_walking_event_id, events_mod_start,\n",
    "        gap_sample_length, epoch_sample_length, n_samples\n",
    "    )\n",
    "\n",
    "    # Define the event dictionary\n",
    "    event_dict = {\n",
    "        'mod_start': mod_start_event_id,\n",
    "        'normal_walking': normal_walking_event_id\n",
    "    }\n",
    "    \n",
    "    # Preprocessing\n",
    "    ## Apply band-pass filtering to the raw LFP data.\n",
    "    l_freq = 1\n",
    "    h_freq = 50\n",
    "    lfp_raw.filter(l_freq=l_freq, h_freq=h_freq, fir_design='firwin')\n",
    "\n",
    "    ## Remove artifacts from raw LFP data using ICA.\n",
    "    ica_n_components = 6 # 6 = n_channels.\n",
    "    ica = mne.preprocessing.ICA(n_components=ica_n_components, random_state=97, max_iter=800)\n",
    "    print(lfp_raw.ch_names)\n",
    "    ica.fit(lfp_raw)\n",
    "    \n",
    "    # Apply ICA to the raw data\n",
    "    raw_data_clean = ica.apply(lfp_raw)\n",
    "\n",
    "    # Combine events and create epochs\n",
    "    events, epochs = DataProcessor.create_epochs_with_events(\n",
    "        raw_data_clean,\n",
    "        events_mod_start,\n",
    "        normal_walking_events,\n",
    "        mod_start_event_id,\n",
    "        normal_walking_event_id,\n",
    "        epoch_tmin,\n",
    "        epoch_tmax,\n",
    "        event_dict\n",
    "    )\n",
    "\n",
    "    # Store epochs and events    \n",
    "    if s in test_session_idx:\n",
    "        test_all_epochs.append(epochs)\n",
    "        test_all_events.append(events)\n",
    "    else:\n",
    "        train_all_epochs.append(epochs)\n",
    "        train_all_events.append(events)\n",
    "    \n",
    "    Visualise.plot_event_class_histogram(events=epochs.events, \n",
    "                                        event_dict=epochs.event_id, \n",
    "                                        show_fig=False, \n",
    "                                        save_fig=True,\n",
    "                                        file_name=f'plots/{s}_hist.png')\n",
    "\n",
    "    Visualise.plot_event_occurrence(events=epochs.events, \n",
    "                                    epoch_sample_length=epoch_sample_length, \n",
    "                                    lfp_sfreq=lfp_sfreq, \n",
    "                                    gait_modulation_event_id=mod_start_event_id, \n",
    "                                    normal_walking_event_id=normal_walking_event_id, \n",
    "                                    show_fig=False, \n",
    "                                    save_fig=True, \n",
    "                                    file_name=f'plots/{s}_event_classes.png')\n",
    "\n",
    "\n",
    "# Combine all epochs into one object\n",
    "train_all_epochs_combined = mne.concatenate_epochs(train_all_epochs)\n",
    "test_all_epochs_combined = mne.concatenate_epochs(test_all_epochs)\n",
    "\n",
    "# Create a single event array by concatenating\n",
    "train_all_events_combined = np.vstack(train_all_events)\n",
    "train_all_events_combined = train_all_events_combined[np.argsort(train_all_events_combined[:, 0])]  # Sort by onset time\n",
    "\n",
    "test_all_events_combined = np.vstack(test_all_events)\n",
    "test_all_events_combined = test_all_events_combined[np.argsort(test_all_events_combined[:, 0])]  # Sort by onset time\n",
    "\n",
    "# train set\n",
    "Visualise.plot_event_class_histogram(events=train_all_epochs_combined.events,\n",
    "                                    event_dict=epochs.event_id, \n",
    "                                    show_fig=False, \n",
    "                                    save_fig=True,\n",
    "                                    file_name=f'plots/train_all_epochs_combined_hist.png')\n",
    "\n",
    "Visualise.plot_event_occurrence(events=train_all_epochs_combined.events,\n",
    "                                epoch_sample_length=epoch_sample_length, \n",
    "                                lfp_sfreq=lfp_sfreq, \n",
    "                                gait_modulation_event_id=mod_start_event_id, \n",
    "                                normal_walking_event_id=normal_walking_event_id, \n",
    "                                show_fig=False, \n",
    "                                save_fig=True, \n",
    "                                file_name=f'plots/train_all_epochs_combined_event_classes.png')\n",
    "\n",
    "# test set\n",
    "Visualise.plot_event_class_histogram(events=test_all_epochs_combined.events,\n",
    "                                    event_dict=epochs.event_id, \n",
    "                                    show_fig=False, \n",
    "                                    save_fig=True,\n",
    "                                    file_name=f'plots/test_all_epochs_combined_hist.png')\n",
    "\n",
    "Visualise.plot_event_occurrence(events=test_all_epochs_combined.events,\n",
    "                                epoch_sample_length=epoch_sample_length, \n",
    "                                lfp_sfreq=lfp_sfreq, \n",
    "                                gait_modulation_event_id=mod_start_event_id, \n",
    "                                normal_walking_event_id=normal_walking_event_id, \n",
    "                                show_fig=False, \n",
    "                                save_fig=True, \n",
    "                                file_name=f'plots/test_all_epochs_combined_event_classes.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_all_epochs_combined.events.shape[0], train_all_events_combined.shape[0])\n",
    "print(test_all_epochs_combined.events.shape[0], test_all_events_combined.shape[0])\n",
    "\n",
    "nlabels = train_all_epochs_combined.events.shape[0] + test_all_epochs_combined.events.shape[0]\n",
    "\n",
    "print(train_all_epochs_combined.events.shape[0] / nlabels)\n",
    "print(test_all_epochs_combined.events.shape[0] / nlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mod_labels = np.sum(train_all_epochs_combined.events[:, 2] == -1) + np.sum(test_all_epochs_combined.events[:, 2] == -1)\n",
    "\n",
    "print(n_mod_labels)\n",
    "\n",
    "print(np.sum(train_all_epochs_combined.events[:, 2] == -1))\n",
    "print(np.sum(test_all_epochs_combined.events[:, 2] == -1))\n",
    "\n",
    "print(np.sum(train_all_epochs_combined.events[:, 2] == -1) / n_mod_labels)\n",
    "print(np.sum(test_all_epochs_combined.events[:, 2] == -1) / n_mod_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Step 1: Train-test split\n",
    "X_train = train_all_epochs_combined.get_data(copy=True)\n",
    "X_test = test_all_epochs_combined.get_data(copy=True)\n",
    "\n",
    "y_train = train_all_epochs_combined.events[:, -1]\n",
    "y_test = test_all_epochs_combined.events[:, -1]\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')# (n_epochs, n_channels, n_samples_per_epoch)\n",
    "print(f'y_train shape: {y_train.shape}')  # (n_epochs,)\n",
    "print(f'--- Total epochs: {len(y_train)}, with {sum(y_train == -1)} normal walking and {sum(y_train == 1)} event-related gait modulation')\n",
    "\n",
    "print(f'X_test shape: {X_test.shape}')# (n_epochs, n_channels, n_samples_per_epoch)\n",
    "print(f'y_test shape: {y_test.shape}')  # (n_epochs,)\n",
    "print(f'--- Total epochs: {len(y_train)}, with {sum(y_test == -1)} normal walking and {sum(y_test == 1)} event-related gait modulation')\n",
    "\n",
    "# Step 2: Flatten the X array (n_epochs, n_channels, n_samples_per_epoch) -> (n_epochs, n_channels * n_samples_per_epoch)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])\n",
    "\n",
    "\n",
    "# Step 3: Standardize the features (mean=0, std=1)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 4: Train a Logistic Regression model\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 5: Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Output the results\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Output the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw psd\n",
    "spectrum = lfp_raw.compute_psd(method='welch', fmax=50, n_fft=2048)\n",
    "\n",
    "psd_arr = spectrum.get_data()\n",
    "psd_freqs = spectrum.freqs\n",
    "\n",
    "print(f\"PSD data has shape: {psd_arr.shape}  # channels x frequencies\")\n",
    "print(f\"Frequencies has shape: {psd_freqs.shape}  # frequencies\")\n",
    "\n",
    "spectrum.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs psd\n",
    "spectrum = epochs.compute_psd(method='welch', fmax=50)\n",
    "\n",
    "psd_arr = spectrum.get_data()\n",
    "psd_freqs = spectrum.freqs\n",
    "\n",
    "print(f\"PSD data has shape: {psd_arr.shape}  # channels x frequencies\")\n",
    "print(f\"Frequencies has shape: {psd_freqs.shape}  # frequencies\")\n",
    "\n",
    "spectrum.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_raw.filter(l_freq = 1, h_freq=None)\n",
    "# raw_copy.notch_filter(freqs=[5, 10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum = lfp_raw.compute_psd(method='welch', fmax=50, n_fft=2048)\n",
    "\n",
    "psd_arr = spectrum.get_data()\n",
    "psd_freqs = spectrum.freqs\n",
    "\n",
    "print(f\"PSD data has shape: {psd_arr.shape}  # channels x frequencies\")\n",
    "print(f\"Frequencies has shape: {psd_freqs.shape}  # frequencies\")\n",
    "\n",
    "spectrum.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_raw.compute_psd(method='welch', fmax=50, n_fft=2048).plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICA raw\n",
    "## CODE GOES HERE\n",
    "ica_95PCA = mne.preprocessing.ICA(n_components=0.95, random_state=0)\n",
    "ica_95PCA.fit(inst=lfp_raw)\n",
    "# ica_95PCA.plot_sources(inst=lfp_raw, title=\"ICA sources (95% variance PCA components)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_ica_excluded = ica.apply(inst=lfp_raw.copy())\n",
    "# raw_ica = ica.apply(inst=lfp_raw.copy())\n",
    "\n",
    "# raw_ica_excluded.plot(scalings='auto', start=12, duration=4, title='clraned sensor signals (without noise)')\n",
    "# raw_ica.plot(scalings='auto', start=12, duration=4, title='clraned sensor signals (without noise)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ICA rpochs\n",
    "# ## CODE GOES HERE\n",
    "# ica_95PCA = mne.preprocessing.ICA(n_components=0.95, random_state=0)\n",
    "# ica_95PCA.fit(inst=epochs_raw)\n",
    "# ica_95PCA.plot_sources(inst=epochs_raw, title=\"ICA sources (95% variance PCA components)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute variance explained by PCA components\n",
    "# explained_variance = ica.pca_explained_variance_ / np.sum(ica.pca_explained_variance_)\n",
    "\n",
    "# print(f\"Variance explained by PCA components: {explained_variance}\")\n",
    "# print(f\"Variance explained by first 4 PCA components: {np.sum(explained_variance[:4]) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ica = mne.preprocessing.ICA(random_state=0)\n",
    "# ica.fit(raw_sensors)\n",
    "\n",
    "# # Remove the first ICA component (the random noise) from the data\n",
    "# raw_cleaned = ica.apply(inst=raw_sensors.copy(), exclude=[1,2])\n",
    "# raw_cleaned.plot(scalings='auto', title='clraned sensor signals (without noise)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_raw[\"mod_start\"].plot_image(combine=\"mean\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_epochs_image(\n",
    "    epochs_raw['mod_start'],\n",
    "    picks=[0, 1, 2, 3, 4, 5],\n",
    "    sigma=0.5,\n",
    "    # combine=\"mean\",\n",
    "    # evoked=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evoked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evoked_0 = epochs_raw['trial_start'].average()\n",
    "evoked_4 = epochs_raw['mod_start'].average()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Field Power (GFP)\n",
    "\n",
    "The GFP is the population standard deviation of the signal across channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig0 = evoked_0.plot(gfp=True);\n",
    "fig1 = evoked_1.plot(gfp=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked_0.plot(gfp=\"only\");\n",
    "evoked_1.plot(gfp=\"only\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfp = evoked_0.data.std(axis=0, ddof=0)\n",
    "\n",
    "# Reproducing the MNE-Python plot style seen above\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(evoked_0.times, gfp * 1e6, color=\"lime\")\n",
    "ax.fill_between(evoked_0.times, gfp * 1e6, color=\"lime\", alpha=0.2)\n",
    "ax.set(xlabel=\"Time (s)\", ylabel=\"GFP (µV)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfp = evoked_1.data.std(axis=0, ddof=0)\n",
    "\n",
    "# Reproducing the MNE-Python plot style seen above\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(evoked_1.times, gfp * 1e6, color=\"lime\")\n",
    "ax.fill_between(evoked_1.times, gfp * 1e6, color=\"lime\", alpha=0.2)\n",
    "ax.set(xlabel=\"Time (s)\", ylabel=\"GFP (µV)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Time-frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.arange(2, 50, 2) # Frequencies from 2 to 50 Hz\n",
    "n_cycles = freqs / 2 # Number of cycles in Morlet wavelet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.arange(7, 30, 3)\n",
    "power = epochs_raw['mod_start'].compute_tfr(\n",
    "    \"morlet\", \n",
    "    n_cycles=2,\n",
    "    return_itc=False, \n",
    "    freqs=freqs,\n",
    "    decim=3,\n",
    "    average=True\n",
    ")\n",
    "power.plot(title='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.arange(7, 30, 3)\n",
    "power = epochs_raw['min_vel'].compute_tfr(\n",
    "    \"morlet\", \n",
    "    n_cycles=2,\n",
    "    return_itc=False, \n",
    "    freqs=freqs,\n",
    "    decim=3,\n",
    "    average=True\n",
    ")\n",
    "power.plot(title='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csd_fft = mne.time_frequency.csd_fourier(epochs_raw, fmin=1, fmax=70)\n",
    "csd_mt = mne.time_frequency.csd_multitaper(epochs_raw, fmin=1, fmax=70, adaptive=True)\n",
    "frequencies = np.arange(1,71, 1)\n",
    "csd_wav = mne.time_frequency.csd_morlet(epochs_raw, frequencies, decim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dict = {\n",
    "    \"Short-time Fourier transform\": csd_fft,\n",
    "    \"Adaptive multitapers\": csd_mt,\n",
    "    \"Morlet wavelet transform\": csd_wav,\n",
    "}\n",
    "for title, csd in plot_dict.items():\n",
    "    (fig,) = csd.mean().plot()\n",
    "    fig.suptitle(title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
