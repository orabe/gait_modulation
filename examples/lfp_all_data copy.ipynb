{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import mne\n",
    "\n",
    "from gait_modulation.file_reader import MatFileReader\n",
    "from gait_modulation.data_processor import DataProcessor\n",
    "from gait_modulation.viz import Visualise\n",
    "from gait_modulation.feature_extractor import FeatureExtractor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from file: /Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/Chiara/organized_data/EM_FH_HK/PW_HK59/26_10_22/walking_sync_2_short.mat\n",
      "Loading data from file: /Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/Chiara/organized_data/EM_FH_HK/PW_HK59/26_10_22/walking_sync_3_short.mat\n",
      "Loading data from file: /Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/Chiara/organized_data/EM_FH_HK/PW_FH57/no_date/walking_sync_4_short.mat\n",
      "Loading data from file: /Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/Chiara/organized_data/EM_FH_HK/PW_FH57/no_date/walking_sync_2_short.mat\n",
      "Loading data from file: /Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/Chiara/organized_data/EM_FH_HK/PW_FH57/no_date/walking_sync_3_short.mat\n",
      "Loading data from file: /Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/Chiara/organized_data/EM_FH_HK/PW_EM59/21_07_2023/walking_sync_4_short.mat\n",
      "Loading data from file: /Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/Chiara/organized_data/EM_FH_HK/PW_EM59/21_07_2023/walking_sync_3_short.mat\n",
      "Loading data from file: /Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/Chiara/organized_data/HZ_SN_SN_US/PW_HZ58/15_09_23/walking_sync_6_short.mat\n",
      "Loading data from file: /Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/Chiara/organized_data/HZ_SN_SN_US/PW_HZ58/15_09_23/walking_sync_4_short.mat\n",
      "Loading data from file: /Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/Chiara/organized_data/HZ_SN_SN_US/PW_HZ58/15_09_23/walking_sync_3_short.mat\n",
      "Loading data from file: /Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/Chiara/organized_data/HZ_SN_SN_US/PW_US68/15_02_23/walking_sync_1_short.mat\n",
      "Loading data from file: /Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/Chiara/organized_data/HZ_SN_SN_US/PW_SN66/20_09_23/walking_sync_1_short.mat\n",
      "Loading data from file: /Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/Chiara/organized_data/HZ_SN_SN_US/PW_SN61/20_03_23/walking_sync_1_short.mat\n",
      "Loading data from file: /Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/Chiara/organized_data/HZ_SN_SN_US/PW_SN61/20_03_23/walking_sync_4_short.mat\n",
      "Loading data from file: /Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/Chiara/organized_data/HZ_SN_SN_US/PW_SN61/20_03_23/walking_sync_2_short.mat\n",
      "Loading data from file: /Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/Chiara/organized_data/HZ_SN_SN_US/PW_SN61/20_03_23/walking_sync_3_short.mat\n",
      "Number of sessions: 16\n"
     ]
    }
   ],
   "source": [
    "# Handle multiple patients with nested directories.\n",
    "root_directory = '/Users/orabe/Library/Mobile Documents/com~apple~CloudDocs/0_TU/Master/master_thesis/Chiara/organized_data'\n",
    "mat_reader = MatFileReader(root_directory, max_workers=1)  #  adjust the number of workers for parallelism\n",
    "\n",
    "# Read all data from nested folders of multiple patients and sessions\n",
    "all_data = mat_reader.read_data()\n",
    "n_sessions = len(all_data)\n",
    "\n",
    "print(f\"Number of sessions: {n_sessions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access specific sessions for a patient\n",
    "session = all_data[0] # pick any session e.g. first one to load the meta data\n",
    "\n",
    "# Extract LFP meta data for subject/session\n",
    "lfp_metadata = DataProcessor.np_to_dict(session['hdr_LFP'])\n",
    "\n",
    "# Load LFP parameters\n",
    "lfp_sfreq = lfp_metadata['Fs'].item()\n",
    "lfp_ch_names = DataProcessor.rename_lfp_channels(lfp_metadata['labels'])\n",
    "lfp_n_channels = lfp_metadata['NumberOfChannels'].item()\n",
    "\n",
    "# Prepare for mne data structure\n",
    "info = mne.create_info(ch_names=lfp_ch_names[0:6], sfreq=lfp_sfreq, ch_types='dbs', verbose=40)\n",
    "\n",
    "# Select one event to work with: mod_start\n",
    "event_of_interest = 'mod_start'\n",
    "mod_start_event_id = 1\n",
    "\n",
    "# Define normal walking events\n",
    "normal_walking_event_id = -1\n",
    "\n",
    "# Define the event dictionary\n",
    "event_dict = {\n",
    "    'mod_start': mod_start_event_id,\n",
    "    'normal_walking': normal_walking_event_id\n",
    "}\n",
    "\n",
    "# Define parameters\n",
    "epoch_tmin = -3.0\n",
    "epoch_tmax = 0.0\n",
    "epoch_duration = epoch_tmax - epoch_tmin\n",
    "epoch_sample_length = int(epoch_duration * lfp_sfreq)\n",
    "gap_duration = 5  # At least 10 seconds away from modulation events\n",
    "gap_sample_length = int(gap_duration * lfp_sfreq)\n",
    "\n",
    "epochs_list = []\n",
    "events_list = []\n",
    "\n",
    "for s in range(n_sessions):\n",
    "    print(f'Session: {s}')\n",
    "    session = all_data[s] # Access specific patient/sessions\n",
    "\n",
    "    # Extract events and lfp data of the subject/session\n",
    "    lfp_data = session['data_LFP'] * 1e-6  # Convert microvolts to volts\n",
    "    \n",
    "    # lfp_raw = mne.io.RawArray(lfp_data, info, verbose=40)\n",
    "    # lfp_raw.plot(start=0, duration=np.inf, remove_dc=False)\n",
    "    # plt.show()\n",
    "\n",
    "    # Handle events\n",
    "    events_KIN = DataProcessor.np_to_dict(session['events_KIN'])\n",
    "    events_before_trim, event_dict_before_trim = DataProcessor.create_events_array(events_KIN, lfp_sfreq)\n",
    "\n",
    "    # Trim the data and adjust the event onsets accordingly\n",
    "    lfp_data, events_after_trim = DataProcessor.trim_data(lfp_data, events_before_trim, lfp_sfreq)\n",
    "    lfp_duration = lfp_data.shape[1] / lfp_sfreq\n",
    "    n_samples = int(lfp_duration * lfp_sfreq)\n",
    "\n",
    "    # Update raw data after trimming\n",
    "    lfp_raw = mne.io.RawArray(lfp_data, info, verbose=40)\n",
    "\n",
    "    # events_mod_start = events_before_trim[events_before_trim[:, 2] == event_dict_before_trim[event_of_interest]]\n",
    "    events_mod_start = events_after_trim[events_after_trim[:, 2] == event_dict_before_trim[event_of_interest]]\n",
    "    events_mod_start[:, 1] = s # mark the session nr  \n",
    "    # print(\"--->\", np.unique(events_mod_start[:, 1]), np.unique(events_mod_start[:, 2], return_counts=True))\n",
    "\n",
    "    # Rename Gait Modulation Events\n",
    "    events_mod_start[:, 2] = mod_start_event_id\n",
    "        \n",
    "    # Define normal walking events\n",
    "    normal_walking_events = DataProcessor.define_normal_walking_events(\n",
    "        normal_walking_event_id, events_mod_start,\n",
    "        gap_sample_length, epoch_sample_length, n_samples\n",
    "    )\n",
    "    \n",
    "    events_mod_start[:, 1] = s # mark the session nr\n",
    "    normal_walking_events[:, 1] = s # mark the session nr\n",
    "\n",
    "    # ## Remove artifacts from raw LFP data using ICA.\n",
    "    # ica_n_components = 6 # 6 = n_channels.\n",
    "    # ica = mne.preprocessing.ICA(n_components=ica_n_components, random_state=97, max_iter=800, verbose=40)\n",
    "    # print(lfp_raw.ch_names)\n",
    "    # ica.fit(lfp_raw)\n",
    "    # raw_data_clean = ica.apply(lfp_raw, verbose=40) # Apply ICA to the raw data\n",
    "\n",
    "    # Combine events and create epochs\n",
    "    events, epochs = DataProcessor.create_epochs_with_events(\n",
    "        lfp_raw,\n",
    "        events_mod_start,\n",
    "        normal_walking_events,\n",
    "        mod_start_event_id,\n",
    "        normal_walking_event_id,\n",
    "        epoch_tmin,\n",
    "        epoch_tmax,\n",
    "        event_dict\n",
    "    )\n",
    "    print(f\"Total epochs: {len(epochs)}\")\n",
    "    for cls in event_dict.keys():\n",
    "        print(f\"{cls}: {len(epochs[cls])} epochs\", end='; ')\n",
    "    \n",
    "    # events[:, 1] = s # No need to mark the session nr for events again!\n",
    "    epochs.events[:, 1] = s # mark the session nr\n",
    "    \n",
    "    my_annot = mne.Annotations(\n",
    "        onset=(events[:, 0] - epoch_sample_length) / lfp_sfreq,  # in seconds\n",
    "        # onset=events[:, 0]/lfp_sfreq,  # in seconds\n",
    "        duration=len(events)*[epoch_duration],  # in seconds, too\n",
    "        description=events[:, 2],\n",
    "    )\n",
    "    lfp_raw.set_annotations(my_annot)\n",
    "    \n",
    "    fig = lfp_raw.plot(start=0, duration=np.inf, show=False) # lfp_duration\n",
    "    fig.suptitle(f'Session {s}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/session{s}.png')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    epochs_list.append(epochs)\n",
    "    events_list.append(events)\n",
    "    \n",
    "    print(\"\\n==========================================================\")\n",
    "\n",
    "\n",
    "epochs = mne.concatenate_epochs(epochs_list, verbose=40)\n",
    "events = np.vstack(events_list)\n",
    "events = events[np.argsort(events[:, 0])]  # TODO: Sort by onset time\n",
    "\n",
    "# Preprocessing\n",
    "## Apply band-pass filtering to the raw LFP data.\n",
    "l_freq = 1\n",
    "h_freq = 50\n",
    "epochs.filter(l_freq=l_freq, h_freq=h_freq, fir_design='firwin', verbose=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualise.plot_event_occurrence(events=events, \n",
    "                                epoch_sample_length=epoch_sample_length, \n",
    "                                lfp_sfreq=lfp_sfreq, \n",
    "                                event_dict=event_dict,\n",
    "                                # gait_modulation_event_id=mod_start_event_id, \n",
    "                                # normal_walking_event_id=normal_walking_event_id, \n",
    "                                n_sessions=n_sessions,\n",
    "                                show_fig=False, \n",
    "                                save_fig=True, \n",
    "                                file_name=f'plots/event_classes.png')\n",
    "\n",
    "\n",
    "Visualise.plot_event_occurrence(events=epochs.events, \n",
    "                                epoch_sample_length=epoch_sample_length, \n",
    "                                lfp_sfreq=lfp_sfreq, \n",
    "                                event_dict=event_dict,\n",
    "                                # gait_modulation_event_id=mod_start_event_id, \n",
    "                                # normal_walking_event_id=normal_walking_event_id, \n",
    "                                n_sessions=n_sessions,\n",
    "                                show_fig=False, \n",
    "                                save_fig=True, \n",
    "                                file_name=f'plots/epochs.event_classes.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualise.plot_event_class_histogram(events=events,\n",
    "                                    event_dict=epochs.event_id,\n",
    "                                    n_sessions=n_sessions,\n",
    "                                    show_fig=False, \n",
    "                                    save_fig=True,\n",
    "                                    file_name=f'plots/event_class_histogram.png')\n",
    "\n",
    "Visualise.plot_event_class_histogram(events=epochs.events,\n",
    "                                    event_dict=epochs.event_id,\n",
    "                                    n_sessions=n_sessions,\n",
    "                                    show_fig=False, \n",
    "                                    save_fig=True,\n",
    "                                    file_name=f'plots/epochs.event_class_histogram.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.save(\"processd/lfp_epo.fif\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import mne\n",
    "\n",
    "from gait_modulation.file_reader import MatFileReader\n",
    "from gait_modulation.data_processor import DataProcessor\n",
    "from gait_modulation.viz import Visualise\n",
    "from gait_modulation.feature_extractor import FeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = mne.read_epochs('processd/lfp_epo.fif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.get_data(copy=False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_bands = {\n",
    "    'delta': (1, 4),\n",
    "    'theta': (4, 8),\n",
    "    'alpha': (8, 13),\n",
    "    'beta': (13, 30),\n",
    "    'gamma': (30, 60)\n",
    "}\n",
    "\n",
    "# Both classes features\n",
    "psd = FeatureExtractor.extract_band_psd(epochs, freq_bands)\n",
    "print(psd['gamma'].shape) # ((freq band: {n_epochs, n_channels, n_frequencies})\n",
    "\n",
    "\n",
    "band_power = FeatureExtractor.extract_band_power(epochs, freq_bands)\n",
    "print(band_power['delta'].shape) # (freq band: {n_epochs x n_channels})\n",
    "\n",
    "# ------------------------\n",
    "# mod_start features\n",
    "psd_mod_start = FeatureExtractor.extract_band_psd(\n",
    "    epochs['mod_start'], freq_bands)\n",
    "print(psd_mod_start['gamma'].shape) # ((freq band: {n_epochs, n_channels, n_frequencies})\n",
    "\n",
    "band_power_mod_start = FeatureExtractor.extract_band_power(\n",
    "    epochs['mod_start'], freq_bands)\n",
    "print(band_power_mod_start['delta'].shape) # (freq band: {n_epochs, n_channels})\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# normal_walking features\n",
    "psd_normal_walking = FeatureExtractor.extract_band_psd(\n",
    "    epochs['normal_walking'], freq_bands)\n",
    "print(psd_normal_walking['gamma'].shape) # ((freq band: {n_epochs, n_channels, n_frequencies})\n",
    "\n",
    "band_power_normal_walking = FeatureExtractor.extract_band_power(\n",
    "    epochs['normal_walking'], freq_bands)\n",
    "print(band_power_normal_walking['delta'].shape) # (freq band: {n_epochs, n_channels})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------\")\n",
    "k=0\n",
    "for band in freq_bands:\n",
    "    k += np.sum(band_power[band].shape[1]) \n",
    "    print(band_power[band].shape)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_band_power(band_power_features):\n",
    "    \"\"\"\n",
    "    Visualizes the band power features stored in a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - band_power_features: dict\n",
    "        Dictionary where keys are frequency bands and values are arrays of shape (epochs, channels).\n",
    "    \"\"\"\n",
    "    # Set up the figure and axes\n",
    "    n_bands = len(band_power_features)\n",
    "    fig, axes = plt.subplots(1, n_bands, figsize=(5 * n_bands, 5), sharey=True)\n",
    "\n",
    "    for ax, (band, data) in zip(axes, band_power_features.items()):\n",
    "        # Calculate mean and standard deviation across epochs for each channel\n",
    "        mean_power = np.mean(data, axis=0)  # Mean across epochs\n",
    "        std_power = np.std(data, axis=0)    # Std deviation across epochs\n",
    "\n",
    "        # Plot mean band power for each channel\n",
    "        ax.plot(mean_power, label=f'Mean Power - {band}', color='blue', marker='o')\n",
    "        ax.fill_between(range(data.shape[1]), mean_power - std_power, mean_power + std_power, \n",
    "                        color='blue', alpha=0.2, label='Std Dev')\n",
    "        \n",
    "        ax.set_title(f'Band Power - {band}', fontsize=14)\n",
    "        ax.set_ylabel('Power (dB)')\n",
    "        ax.set_xlabel('Channels')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.xticks(ticks=range(data.shape[1]), labels=[f'Channel {i+1}' for i in range(data.shape[1])])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming `band_power_features` is a dictionary containing the band power data.\n",
    "visualize_band_power(band_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_band_power(band_power_features_mod, band_power_features_norm):\n",
    "    \"\"\"\n",
    "    Visualizes the band power features for mod_start and normal_walking classes.\n",
    "\n",
    "    Parameters:\n",
    "    - band_power_features_mod: dict\n",
    "        Dictionary for mod_start where keys are frequency bands and values are arrays of shape (epochs, channels).\n",
    "    - band_power_features_norm: dict\n",
    "        Dictionary for normal_walking where keys are frequency bands and values are arrays of shape (epochs, channels).\n",
    "    \"\"\"\n",
    "    # Set up the figure and axes\n",
    "    n_bands = len(band_power_features_mod)\n",
    "    fig, axes = plt.subplots(1, n_bands, figsize=(5 * n_bands, 5), sharey=True)\n",
    "\n",
    "    for ax, (band, data_mod), (_, data_norm) in zip(axes, band_power_features_mod.items(), band_power_features_norm.items()):\n",
    "        # Calculate mean across epochs for each channel\n",
    "        mean_power_mod = np.mean(data_mod, axis=0)  # Mean across epochs for mod_start\n",
    "        mean_power_norm = np.mean(data_norm, axis=0)  # Mean across epochs for normal_walking\n",
    "\n",
    "        # Plot mean band power for mod_start\n",
    "        ax.plot(mean_power_mod, label='mod_start', color='blue', marker='o')\n",
    "\n",
    "        # Plot mean band power for normal_walking\n",
    "        ax.plot(mean_power_norm, label='normal_walking', color='orange', marker='o')\n",
    "\n",
    "        ax.set_title(f'Band Power - {band}', fontsize=14)\n",
    "        ax.set_ylabel('Power (dB)')\n",
    "        ax.set_xlabel('Channels')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.xticks(ticks=range(data_mod.shape[1]), labels=[f'Channel {i+1}' for i in range(data_mod.shape[1])])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "visualize_band_power(band_power_mod_start, band_power_normal_walking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_psd(psd_features):\n",
    "    \"\"\"\n",
    "    Visualizes the PSD features for each frequency band.\n",
    "    \n",
    "    Parameters:\n",
    "    - psd_features: Dictionary with frequency bands as keys and values as \n",
    "                    arrays of shape (n_epochs, n_channels, n_frequencies).\n",
    "    \"\"\"\n",
    "    num_bands = len(psd_features)\n",
    "    num_channels = next(iter(psd_features.values())).shape[1]  # Get number of channels\n",
    "\n",
    "    # Create a figure with subplots for each frequency band\n",
    "    fig, axes = plt.subplots(1, num_bands, figsize=(5 * num_bands, 5), sharey=True)\n",
    "    \n",
    "    # Plot each band\n",
    "    for i, (band, values) in enumerate(psd_features.items()):\n",
    "        mean_psd = values.mean(axis=0)  # Average across epochs\n",
    "        freq_range = freq_bands[band]\n",
    "        freqs = np.linspace(freq_range[0], freq_range[1], values.shape[2])  # Adjust frequency range per band\n",
    "        \n",
    "        for ch in range(num_channels):\n",
    "            axes[i].plot(freqs, mean_psd[ch, :], label=f'Channel {ch + 1}')\n",
    "        \n",
    "        # Add titles and labels\n",
    "        axes[i].set_title(f'PSD Features - {band.capitalize()} band', fontsize=16)\n",
    "        axes[i].set_xlabel('Frequency (Hz)', fontsize=14)\n",
    "        if i == 0:\n",
    "            axes[i].set_ylabel('PSD', fontsize=14)\n",
    "        axes[i].legend(loc='upper right')\n",
    "        axes[i].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example data for testing (use your actual psd_features data here)\n",
    "visualize_psd(psd)  # Uncomment and run with actual psd_features data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_psd_by_class(psd_features_mod, psd_features_norm, freq_bands):\n",
    "    \"\"\"\n",
    "    Visualizes the PSD features for each frequency band in two subplots, one for each class (mod_start and normal_walking).\n",
    "    \n",
    "    Parameters:\n",
    "    - psd_features_mod: Dictionary for mod_start class with frequency bands as keys and \n",
    "                        values as arrays of shape (n_epochs, n_channels, n_frequencies).\n",
    "    - psd_features_norm: Dictionary for normal_walking class with frequency bands as keys and \n",
    "                         values as arrays of shape (n_epochs, n_channels, n_frequencies).\n",
    "    - freq_bands: Dictionary of frequency bands with their ranges.\n",
    "    \"\"\"\n",
    "    num_bands = len(freq_bands)\n",
    "    num_channels_mod = next(iter(psd_features_mod.values())).shape[1]  # Number of channels for mod_start\n",
    "    num_channels_norm = next(iter(psd_features_norm.values())).shape[1]  # Number of channels for normal_walking\n",
    "\n",
    "    fig, axes = plt.subplots(2, num_bands, figsize=(5 * num_bands, 10), sharey=True)\n",
    "\n",
    "    # Plot PSD for mod_start\n",
    "    for i, (band, values_mod) in enumerate(psd_features_mod.items()):\n",
    "        mean_psd_mod = values_mod.mean(axis=0)  # Average across epochs for mod_start\n",
    "        freq_range = freq_bands[band]\n",
    "        freqs = np.linspace(freq_range[0], freq_range[1], values_mod.shape[2])  # Set frequency range per band\n",
    "        \n",
    "        for ch in range(num_channels_mod):\n",
    "            axes[0, i].plot(freqs, mean_psd_mod[ch, :], label=f'Channel {ch + 1}')\n",
    "        \n",
    "        # Add titles and labels for mod_start class\n",
    "        axes[0, i].set_title(f'mod_start - {band.capitalize()}', fontsize=14)\n",
    "        axes[0, i].set_xlabel('Frequency (Hz)', fontsize=12)\n",
    "        if i == 0:\n",
    "            axes[0, i].set_ylabel('PSD', fontsize=12)\n",
    "        axes[0, i].grid(True)\n",
    "\n",
    "    # Plot PSD for normal_walking\n",
    "    for i, (band, values_norm) in enumerate(psd_features_norm.items()):\n",
    "        mean_psd_norm = values_norm.mean(axis=0)  # Average across epochs for normal_walking\n",
    "        freq_range = freq_bands[band]\n",
    "        freqs = np.linspace(freq_range[0], freq_range[1], values_norm.shape[2])  # Set frequency range per band\n",
    "        \n",
    "        for ch in range(num_channels_norm):\n",
    "            axes[1, i].plot(freqs, mean_psd_norm[ch, :], label=f'Channel {ch + 1}')\n",
    "        \n",
    "        # Add titles and labels for normal_walking class\n",
    "        axes[1, i].set_title(f'normal_walking - {band.capitalize()}', fontsize=14)\n",
    "        axes[1, i].set_xlabel('Frequency (Hz)', fontsize=12)\n",
    "        if i == 0:\n",
    "            axes[1, i].set_ylabel('PSD', fontsize=12)\n",
    "        axes[1, i].grid(True)\n",
    "\n",
    "    # Add legends and adjust layout\n",
    "    for ax in axes.flat:\n",
    "        ax.legend(loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "psd_features_mod_start = FeatureExtractor.extract_band_psd(epochs['mod_start'], freq_bands)\n",
    "psd_features_normal_walking = FeatureExtractor.extract_band_psd(epochs['normal_walking'], freq_bands)\n",
    "\n",
    "visualize_psd_by_class(psd_features_mod_start, psd_features_normal_walking, freq_bands)  # Uncomment with actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def visualize_psd_by_class(psd_features_mod, psd_features_norm, freq_bands):\n",
    "#     \"\"\"\n",
    "#     Visualizes the PSD features for each frequency band in two subplots, one for each class (mod_start and normal_walking),\n",
    "#     with frequency bands spread along the y-axis.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - psd_features_mod: Dictionary for mod_start class with frequency bands as keys and \n",
    "#                         values as arrays of shape (n_epochs, n_channels, n_frequencies).\n",
    "#     - psd_features_norm: Dictionary for normal_walking class with frequency bands as keys and \n",
    "#                          values as arrays of shape (n_epochs, n_channels, n_frequencies).\n",
    "#     - freq_bands: Dictionary of frequency bands with their ranges.\n",
    "#     \"\"\"\n",
    "#     num_bands = len(freq_bands)\n",
    "#     num_channels_mod = next(iter(psd_features_mod.values())).shape[1]  # Number of channels for mod_start\n",
    "#     num_channels_norm = next(iter(psd_features_norm.values())).shape[1]  # Number of channels for normal_walking\n",
    "\n",
    "#     fig, axes = plt.subplots(num_bands, 2, figsize=(10, 5 * num_bands), sharey=True)\n",
    "\n",
    "#     # Plot each frequency band on a separate row\n",
    "#     for i, (band, values_mod) in enumerate(psd_features_mod.items()):\n",
    "#         # Define frequency range for this band\n",
    "#         freq_range = freq_bands[band]\n",
    "#         freqs = np.linspace(freq_range[0], freq_range[1], values_mod.shape[2])\n",
    "\n",
    "#         # Plot mod_start PSD in the left column\n",
    "#         mean_psd_mod = values_mod.mean(axis=0)  # Average across epochs\n",
    "#         for ch in range(num_channels_mod):\n",
    "#             axes[i, 0].plot(freqs, mean_psd_mod[ch, :], label=f'Channel {ch + 1}')\n",
    "        \n",
    "#         # Add title and labels for mod_start\n",
    "#         axes[i, 0].set_title(f'{band.capitalize()} - mod_start', fontsize=14)\n",
    "#         axes[i, 0].set_ylabel('PSD', fontsize=12)\n",
    "#         axes[i, 0].grid(True)\n",
    "#         if i == num_bands - 1:\n",
    "#             axes[i, 0].set_xlabel('Frequency (Hz)', fontsize=12)\n",
    "\n",
    "#         # Plot normal_walking PSD in the right column\n",
    "#         values_norm = psd_features_norm[band]\n",
    "#         mean_psd_norm = values_norm.mean(axis=0)  # Average across epochs\n",
    "#         for ch in range(num_channels_norm):\n",
    "#             axes[i, 1].plot(freqs, mean_psd_norm[ch, :], label=f'Channel {ch + 1}')\n",
    "        \n",
    "#         # Add title and labels for normal_walking\n",
    "#         axes[i, 1].set_title(f'{band.capitalize()} - normal_walking', fontsize=14)\n",
    "#         axes[i, 1].grid(True)\n",
    "#         if i == num_bands - 1:\n",
    "#             axes[i, 1].set_xlabel('Frequency (Hz)', fontsize=12)\n",
    "\n",
    "#     # Add legends and adjust layout\n",
    "#     for ax in axes.flat:\n",
    "#         ax.legend(loc='upper right')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# psd_features_mod_start = FeatureExtractor.extract_band_psd(epochs['mod_start'], freq_bands)\n",
    "# psd_features_normal_walking = FeatureExtractor.extract_band_psd(epochs['normal_walking'], freq_bands)\n",
    "\n",
    "# visualize_psd_by_class(psd_features_mod_start, psd_features_normal_walking, freq_bands)  # Uncomment with actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_psd_by_class(psd_features_mod, psd_features_norm, freq_bands):\n",
    "    \"\"\"\n",
    "    Visualizes the PSD features for each frequency band in two subplots, one for each class (mod_start and normal_walking),\n",
    "    with frequency bands spread along the y-axis. Includes individual channel plots with an overlay of the mean and\n",
    "    standard deviation across channels.\n",
    "    \n",
    "    Parameters:\n",
    "    - psd_features_mod: Dictionary for mod_start class with frequency bands as keys and \n",
    "                        values as arrays of shape (n_epochs, n_channels, n_frequencies).\n",
    "    - psd_features_norm: Dictionary for normal_walking class with frequency bands as keys and \n",
    "                         values as arrays of shape (n_epochs, n_channels, n_frequencies).\n",
    "    - freq_bands: Dictionary of frequency bands with their ranges.\n",
    "    \"\"\"\n",
    "    num_bands = len(freq_bands)\n",
    "    num_channels_mod = next(iter(psd_features_mod.values())).shape[1]  # Number of channels for mod_start\n",
    "    num_channels_norm = next(iter(psd_features_norm.values())).shape[1]  # Number of channels for normal_walking\n",
    "\n",
    "    fig, axes = plt.subplots(num_bands, 2, figsize=(10, 5 * num_bands), sharey=True)\n",
    "\n",
    "    # Plot each frequency band on a separate row\n",
    "    for i, (band, values_mod) in enumerate(psd_features_mod.items()):\n",
    "        # Define frequency range for this band\n",
    "        freq_range = freq_bands[band]\n",
    "        freqs = np.linspace(freq_range[0], freq_range[1], values_mod.shape[2])\n",
    "\n",
    "        # Plot mod_start PSD for each channel\n",
    "        mean_psd_mod = values_mod.mean(axis=0)  # Average across epochs\n",
    "        std_psd_mod = values_mod.std(axis=0)  # Standard deviation across epochs\n",
    "        mean_across_channels_mod = mean_psd_mod.mean(axis=0)  # Mean across channels\n",
    "        std_across_channels_mod = mean_psd_mod.std(axis=0)  # Std across channels\n",
    "        \n",
    "        for ch in range(num_channels_mod):\n",
    "            axes[i, 0].plot(freqs, mean_psd_mod[ch, :], label=f'Channel {ch + 1}', alpha=0.6)\n",
    "\n",
    "        # Overlay mean line and standard deviation shading for mod_start\n",
    "        axes[i, 0].plot(freqs, mean_across_channels_mod, color='black', linewidth=2, label='Mean')\n",
    "        axes[i, 0].fill_between(freqs, mean_across_channels_mod - std_across_channels_mod,\n",
    "                                mean_across_channels_mod + std_across_channels_mod, color='gray', alpha=0.3, label='±1 STD')\n",
    "        \n",
    "        # Add title and labels for mod_start\n",
    "        axes[i, 0].set_title(f'{band.capitalize()} - mod_start', fontsize=14)\n",
    "        axes[i, 0].set_ylabel('PSD', fontsize=12)\n",
    "        axes[i, 0].grid(True)\n",
    "        if i == num_bands - 1:\n",
    "            axes[i, 0].set_xlabel('Frequency (Hz)', fontsize=12)\n",
    "\n",
    "        # Plot normal_walking PSD for each channel\n",
    "        values_norm = psd_features_norm[band]\n",
    "        mean_psd_norm = values_norm.mean(axis=0)  # Average across epochs\n",
    "        std_psd_norm = values_norm.std(axis=0)  # Standard deviation across epochs\n",
    "        mean_across_channels_norm = mean_psd_norm.mean(axis=0)  # Mean across channels\n",
    "        std_across_channels_norm = mean_psd_norm.std(axis=0)  # Std across channels\n",
    "        \n",
    "        for ch in range(num_channels_norm):\n",
    "            axes[i, 1].plot(freqs, mean_psd_norm[ch, :], label=f'Channel {ch + 1}', alpha=0.6)\n",
    "        \n",
    "        # Overlay mean line and standard deviation shading for normal_walking\n",
    "        axes[i, 1].plot(freqs, mean_across_channels_norm, color='black', linewidth=2, label='Mean')\n",
    "        axes[i, 1].fill_between(freqs, mean_across_channels_norm - std_across_channels_norm,\n",
    "                                mean_across_channels_norm + std_across_channels_norm, color='gray', alpha=0.3, label='±1 STD')\n",
    "\n",
    "        # Add title and labels for normal_walking\n",
    "        axes[i, 1].set_title(f'{band.capitalize()} - normal_walking', fontsize=14)\n",
    "        axes[i, 1].grid(True)\n",
    "        if i == num_bands - 1:\n",
    "            axes[i, 1].set_xlabel('Frequency (Hz)', fontsize=12)\n",
    "\n",
    "    # Add legends and adjust layout\n",
    "    for ax in axes.flat:\n",
    "        ax.legend(loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "psd_features_mod_start = FeatureExtractor.extract_band_psd(epochs['mod_start'], freq_bands)\n",
    "psd_features_normal_walking = FeatureExtractor.extract_band_psd(epochs['normal_walking'], freq_bands)\n",
    "\n",
    "visualize_psd_by_class(psd_features_mod_start, psd_features_normal_walking, freq_bands)  # Uncomment with actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overall_psd_with_bands(epochs, freq_bands, fmin=1, fmax=50):\n",
    "    \"\"\"\n",
    "    Plots the overall PSD averaged across epochs for each channel, and marks the frequency bands with different colors and annotations.\n",
    "\n",
    "    Parameters:\n",
    "    - epochs: mne.Epochs object containing the LFP data.\n",
    "    - freq_bands: Dictionary where keys are the band names, and values are tuples with (low_freq, high_freq).\n",
    "    - fmin: Minimum frequency to compute PSD (default=1 Hz).\n",
    "    - fmax: Maximum frequency to compute PSD (default=50 Hz).\n",
    "    \"\"\"\n",
    "    # Compute PSD across all epochs and channels, averaging across epochs\n",
    "    psds, freqs = epochs.compute_psd(fmin=fmin, fmax=fmax).get_data(return_freqs=True)\n",
    "    psds_mean = psds.mean(axis=0)  # Average across epochs\n",
    "    \n",
    "    # Colors for the frequency bands\n",
    "    band_colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'lightpink']\n",
    "\n",
    "    # Plot overall PSD for each channel\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    for ch in range(psds_mean.shape[0]):  # Iterate over channels\n",
    "        ax.plot(freqs, 10 * np.log10(psds_mean[ch]), label=f'Channel {ch+1}')\n",
    "\n",
    "    # Mark frequency bands with distinct colors and create a secondary x-axis for band names\n",
    "    for i, (band, (low, high)) in enumerate(freq_bands.items()):\n",
    "        ax.axvspan(low, high, color=band_colors[i % len(band_colors)], alpha=0.3)\n",
    "\n",
    "    # Add secondary x-axis to display band names\n",
    "    ax_top = ax.secondary_xaxis('top')\n",
    "    ax_top.set_xticks([np.mean([low, high]) for low, high in freq_bands.values()])  # Place ticks at the center of each band\n",
    "    ax_top.set_xticklabels(freq_bands.keys())  # Set the band names as labels\n",
    "    ax_top.tick_params(axis='x', pad=10)  # Adjust padding of the labels\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Frequency (Hz)')\n",
    "    ax.set_ylabel('Power Spectral Density (dB)')\n",
    "    ax.set_title('Overall PSD Averaged Across Epochs for Each Channel')\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `epochs` is your MNE Epochs object and `freq_bands` is a dictionary of frequency bands\n",
    "plot_overall_psd_with_bands(epochs, freq_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overall_psd_with_bands_by_class(epochs_mod, epochs_norm, freq_bands, fmin=1, fmax=50):\n",
    "    \"\"\"\n",
    "    Plots the overall PSD for two classes (mod_start and normal_walking) in separate subplots,\n",
    "    averaged across epochs for each class and channel. Frequency bands are marked with distinct colors.\n",
    "\n",
    "    Parameters:\n",
    "    - epochs_mod: MNE Epochs object for the mod_start class.\n",
    "    - epochs_norm: MNE Epochs object for the normal_walking class.\n",
    "    - freq_bands: Dictionary where keys are the band names, and values are tuples with (low_freq, high_freq).\n",
    "    - fmin: Minimum frequency to compute PSD (default=1 Hz).\n",
    "    - fmax: Maximum frequency to compute PSD (default=50 Hz).\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute PSD for mod_start class\n",
    "    psds_mod, freqs_mod = epochs_mod.compute_psd(fmin=fmin, fmax=fmax).get_data(return_freqs=True)\n",
    "    psds_mod_mean = psds_mod.mean(axis=0)  # Average across epochs for mod_start\n",
    "\n",
    "    # Compute PSD for normal_walking class\n",
    "    psds_norm, freqs_norm = epochs_norm.compute_psd(fmin=fmin, fmax=fmax).get_data(return_freqs=True)\n",
    "    psds_norm_mean = psds_norm.mean(axis=0)  # Average across epochs for normal_walking\n",
    "\n",
    "    # Colors for the frequency bands\n",
    "    band_colors = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow', 'lightpink']\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6), sharey=True)\n",
    "\n",
    "    # Plot PSD for mod_start\n",
    "    for ch in range(psds_mod_mean.shape[0]):\n",
    "        axes[0].plot(freqs_mod, 10 * np.log10(psds_mod_mean[ch]), label=f'Channel {ch+1}')\n",
    "    axes[0].set_title('PSD for mod_start')\n",
    "    axes[0].set_xlabel('Frequency (Hz)')\n",
    "    axes[0].set_ylabel('Power Spectral Density (dB)')\n",
    "    for i, (band, (low, high)) in enumerate(freq_bands.items()):\n",
    "        axes[0].axvspan(low, high, color=band_colors[i % len(band_colors)], alpha=0.3)\n",
    "    ax_top_mod = axes[0].secondary_xaxis('top')\n",
    "    ax_top_mod.set_xticks([np.mean([low, high]) for low, high in freq_bands.values()])\n",
    "    ax_top_mod.set_xticklabels(freq_bands.keys())\n",
    "    ax_top_mod.tick_params(axis='x', pad=10)\n",
    "\n",
    "    # Plot PSD for normal_walking\n",
    "    for ch in range(psds_norm_mean.shape[0]):\n",
    "        axes[1].plot(freqs_norm, 10 * np.log10(psds_norm_mean[ch]), label=f'Channel {ch+1}')\n",
    "    axes[1].set_title('PSD for normal_walking')\n",
    "    axes[1].set_xlabel('Frequency (Hz)')\n",
    "    for i, (band, (low, high)) in enumerate(freq_bands.items()):\n",
    "        axes[1].axvspan(low, high, color=band_colors[i % len(band_colors)], alpha=0.3)\n",
    "    ax_top_norm = axes[1].secondary_xaxis('top')\n",
    "    ax_top_norm.set_xticks([np.mean([low, high]) for low, high in freq_bands.values()])\n",
    "    ax_top_norm.set_xticklabels(freq_bands.keys())\n",
    "    ax_top_norm.tick_params(axis='x', pad=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "plot_overall_psd_with_bands_by_class(epochs['mod_start'], epochs['normal_walking'], freq_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_overall_psd_with_bands_by_class(epochs_mod, epochs_norm, freq_bands, fmin=1, fmax=50):\n",
    "    \"\"\"\n",
    "    Plots the overall PSD for two classes (mod_start and normal_walking) in one plot,\n",
    "    averaged across epochs and channels. Frequency bands are marked with distinct colors.\n",
    "\n",
    "    Parameters:\n",
    "    - epochs_mod: MNE Epochs object for the mod_start class.\n",
    "    - epochs_norm: MNE Epochs object for the normal_walking class.\n",
    "    - freq_bands: Dictionary where keys are the band names, and values are tuples with (low_freq, high_freq).\n",
    "    - fmin: Minimum frequency to compute PSD (default=1 Hz).\n",
    "    - fmax: Maximum frequency to compute PSD (default=50 Hz).\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute PSD for mod_start class\n",
    "    psds_mod, freqs_mod = epochs_mod.compute_psd(fmin=fmin, fmax=fmax).get_data(return_freqs=True)\n",
    "    psds_mod_mean = psds_mod.mean(axis=(0, 1))  # Average across epochs and channels\n",
    "\n",
    "    # Compute PSD for normal_walking class\n",
    "    psds_norm, freqs_norm = epochs_norm.compute_psd(fmin=fmin, fmax=fmax).get_data(return_freqs=True)\n",
    "    psds_norm_mean = psds_norm.mean(axis=(0, 1))  # Average across epochs and channels\n",
    "\n",
    "    # Colors for the frequency bands\n",
    "    band_colors = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow', 'lightpink']\n",
    "\n",
    "    # Create figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot the mean PSD for mod_start\n",
    "    plt.plot(freqs_mod, 10 * np.log10(psds_mod_mean), color='blue', label='mod_start (mean)', linewidth=2)\n",
    "\n",
    "    # Plot the mean PSD for normal_walking\n",
    "    plt.plot(freqs_norm, 10 * np.log10(psds_norm_mean), color='orange', label='normal_walking (mean)', linewidth=2)\n",
    "\n",
    "    # Mark frequency bands with shaded regions\n",
    "    for i, (band, (low, high)) in enumerate(freq_bands.items()):\n",
    "        plt.axvspan(low, high, color=band_colors[i % len(band_colors)], alpha=0.3)\n",
    "\n",
    "    # Top x-axis for frequency bands\n",
    "    ax_top = plt.gca().secondary_xaxis('top')\n",
    "    ax_top.set_xticks([np.mean([low, high]) for low, high in freq_bands.values()])\n",
    "    ax_top.set_xticklabels(freq_bands.keys())\n",
    "    ax_top.tick_params(axis='x', pad=10)\n",
    "\n",
    "    # Plot settings\n",
    "    plt.title('PSD Comparison for mod_start and normal_walking')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Power Spectral Density (dB)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "plot_overall_psd_with_bands_by_class(epochs['mod_start'], epochs['normal_walking'], freq_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_band_power_combined(band_power_features, sfreq, ch_names):\n",
    "    \"\"\"\n",
    "    Visualizes the band power features stored in a dictionary in a single plot,\n",
    "    with each trace representing a channel and the x-axis representing frequency bands.\n",
    "\n",
    "    Parameters:\n",
    "    - band_power_features: dict\n",
    "        Dictionary where keys are frequency bands and values are arrays of shape (epochs, channels).\n",
    "    - sfreq: float\n",
    "        Sampling frequency of the data.\n",
    "    - ch_names: list\n",
    "        List of channel names corresponding to the data.\n",
    "    \"\"\"\n",
    "    # Create a new figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Prepare the x-axis (frequency bands)\n",
    "    freq_bands = list(band_power_features.keys())\n",
    "    num_bands = len(freq_bands)\n",
    "\n",
    "    # Prepare the y-axis data for each channel\n",
    "    for ch_idx, ch_name in enumerate(ch_names):\n",
    "        # Extract band power data for this channel\n",
    "        channel_band_power = [band_power_features[band][:, ch_idx].mean() for band in freq_bands]\n",
    "\n",
    "        # Plot each channel's band power across frequency bands\n",
    "        plt.plot(freq_bands, channel_band_power, marker='o', label=ch_name)\n",
    "\n",
    "    # Add titles and labels\n",
    "    plt.title('Band Power Across Frequency Bands', fontsize=16)\n",
    "    plt.xlabel('Frequency Bands', fontsize=14)\n",
    "    plt.ylabel('Average Power (dB)', fontsize=14)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid()\n",
    "    plt.legend(title='Channels', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `band_power_features` is your dictionary containing the band power data,\n",
    "# `sfreq` is your sampling frequency, and `ch_names` is your list of channel names.\n",
    "visualize_band_power_combined(band_power, lfp_sfreq, lfp_ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_band_power(band_power_features_mod, band_power_features_norm):\n",
    "    \"\"\"\n",
    "    Visualizes the band power features for mod_start and normal_walking classes.\n",
    "\n",
    "    Parameters:\n",
    "    - band_power_features_mod: dict\n",
    "        Dictionary for mod_start where keys are frequency bands and values are arrays of shape (epochs, channels).\n",
    "    - band_power_features_norm: dict\n",
    "        Dictionary for normal_walking where keys are frequency bands and values are arrays of shape (epochs, channels).\n",
    "    \"\"\"\n",
    "    # Set up the figure and axes\n",
    "    n_bands = len(band_power_features_mod)\n",
    "    fig, axes = plt.subplots(1, n_bands, figsize=(5 * n_bands, 5), sharey=True)\n",
    "\n",
    "    for ax, (band, data_mod), (_, data_norm) in zip(axes, band_power_features_mod.items(), band_power_features_norm.items()):\n",
    "        # Calculate mean and standard deviation across epochs for each channel for mod_start\n",
    "        mean_power_mod = np.mean(data_mod, axis=0)  # Mean across epochs\n",
    "        std_power_mod = np.std(data_mod, axis=0)    # Std deviation across epochs\n",
    "        \n",
    "        # Calculate mean and standard deviation across epochs for each channel for normal_walking\n",
    "        mean_power_norm = np.mean(data_norm, axis=0)  # Mean across epochs\n",
    "        std_power_norm = np.std(data_norm, axis=0)    # Std deviation across epochs\n",
    "\n",
    "        # Plot mean band power for mod_start\n",
    "        ax.plot(mean_power_mod, label=f'Mean Power - mod_start', color='blue', marker='o')\n",
    "        ax.fill_between(range(data_mod.shape[1]), mean_power_mod - std_power_mod, mean_power_mod + std_power_mod, \n",
    "                        color='blue', alpha=0.2, label='Std Dev - mod_start')\n",
    "\n",
    "        # Plot mean band power for normal_walking\n",
    "        ax.plot(mean_power_norm, label=f'Mean Power - normal_walking', color='orange', marker='o')\n",
    "        ax.fill_between(range(data_norm.shape[1]), mean_power_norm - std_power_norm, mean_power_norm + std_power_norm, \n",
    "                        color='orange', alpha=0.2, label='Std Dev - normal_walking')\n",
    "\n",
    "        ax.set_title(f'Band Power - {band}', fontsize=14)\n",
    "        ax.set_ylabel('Power (dB)')\n",
    "        ax.set_xlabel('Channels')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.xticks(ticks=range(data_mod.shape[1]), labels=[f'Channel {i+1}' for i in range(data_mod.shape[1])])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "visualize_band_power(band_power_mod_start, band_power_normal_walking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_power_mod_start['beta'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_band_power_mean_std(band_power_features):\n",
    "    \"\"\"\n",
    "    Visualizes the mean and standard deviation of band power features across channels\n",
    "    in a single plot, with each trace representing the mean and std across channels.\n",
    "\n",
    "    Parameters:\n",
    "    - band_power_features: dict\n",
    "        Dictionary where keys are frequency bands and values are arrays of shape (epochs, channels).\n",
    "    \"\"\"\n",
    "    # Create a new figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Prepare the x-axis (frequency bands)\n",
    "    freq_bands = list(band_power_features.keys())\n",
    "\n",
    "    # Prepare the y-axis data for mean and std across channels\n",
    "    mean_band_power = []\n",
    "    std_band_power = []\n",
    "\n",
    "    for band in freq_bands:\n",
    "        # Compute the mean and standard deviation across channels for the current frequency band\n",
    "        mean_power = band_power_features[band].mean(axis=1)  # Mean across channels\n",
    "        std_power = band_power_features[band].std(axis=1)    # Std across channels\n",
    "        \n",
    "        mean_band_power.append(mean_power)  # Append the mean values\n",
    "        std_band_power.append(std_power)      # Append the std values\n",
    "\n",
    "    mean_band_power = np.array(mean_band_power)\n",
    "    std_band_power = np.array(std_band_power)\n",
    "\n",
    "    # Mean and std for plotting should be calculated correctly\n",
    "    mean_band_power_mean = mean_band_power.mean(axis=1)\n",
    "    mean_band_power_std = mean_band_power.std(axis=1)\n",
    "\n",
    "    # Plotting the mean\n",
    "    plt.plot(freq_bands, mean_band_power_mean, marker='o', label='Mean', color='blue')\n",
    "\n",
    "    # Plotting the standard deviation as shaded area\n",
    "    plt.fill_between(freq_bands, \n",
    "                     mean_band_power_mean - mean_band_power_std, \n",
    "                     mean_band_power_mean + mean_band_power_std, \n",
    "                     color='blue', alpha=0.3, label='Std Dev')\n",
    "\n",
    "    # Add titles and labels\n",
    "    plt.title('Mean Band Power Across Frequency Bands', fontsize=16)\n",
    "    plt.xlabel('Frequency Bands', fontsize=14)\n",
    "    plt.ylabel('Average Power (dB)', fontsize=14)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid()\n",
    "    plt.legend(title='Statistics')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `band_power_features` is your dictionary containing the band power data.\n",
    "visualize_band_power_mean_std(band_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs['mod_start'].plot_image(picks=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad_epoch = np.argmin(epochs['mod_start'].get_data()[76, 5,:]) \n",
    "# # epochs[76, 5, 54] = np.mean(epochs['mod_start'].get_data()[76, 5,:])\n",
    "# # epochs['mod_start'].get_data()[76, 5, 54]\n",
    "# epochs.drop(bad_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def remove_outliers(epochs, threshold=3):\n",
    "\n",
    "# # Compute the mean and standard deviation across epochs\n",
    "# data = epochs.get_data()  # shape: (n_epochs, n_channels, n_times)\n",
    "# threshold=3\n",
    "\n",
    "# # Reshape to (n_epochs, n_channels * n_times)\n",
    "# reshaped_data = data.reshape(data.shape[0], -1)\n",
    "\n",
    "# # Calculate z-scores\n",
    "# z_scores = np.abs((reshaped_data - np.mean(reshaped_data, axis=0)) / np.std(reshaped_data, axis=0))\n",
    "\n",
    "# # Identify outlier epochs\n",
    "# outlier_epochs = np.where(z_scores > threshold)\n",
    "\n",
    "# # Remove outlier epochs\n",
    "# clean_epochs = epochs.copy().drop(outlier_epochs[0])\n",
    "\n",
    "# # cleaned_epochs = remove_outliers(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-Test on Band Power Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize results storage\n",
    "t_stats = {}\n",
    "p_values = {}\n",
    "\n",
    "# Loop through each frequency band\n",
    "for band in band_power_mod_start.keys():\n",
    "    # Average across epochs (axis=0) and channels (axis=1)\n",
    "    mean_mod = np.mean(band_power_mod_start[band], axis=0)\n",
    "    mean_norm = np.mean(band_power_normal_walking[band], axis=0)\n",
    "    \n",
    "    # Perform a t-test\n",
    "    t_stat, p_value = stats.ttest_ind(mean_mod, mean_norm)\n",
    "    \n",
    "    # Store the results\n",
    "    t_stats[band] = t_stat\n",
    "    p_values[band] = p_value\n",
    "\n",
    "# Display results\n",
    "for band in t_stats.keys():\n",
    "    print(f'Band {band}: T-statistic: {t_stats[band]:.4f}, P-value: {p_values[band]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-Test on PSD Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize results storage\n",
    "t_stats_psd = {}\n",
    "p_values_psd = {}\n",
    "\n",
    "# Loop through each frequency band\n",
    "for band in psd_features_mod_start.keys():\n",
    "    # Average across epochs (axis=0) and channels (axis=1) for each frequency\n",
    "    mean_psd_mod = np.mean(psd_features_mod_start[band], axis=(0, 1))  # Mean across epochs and channels\n",
    "    mean_psd_norm = np.mean(psd_features_normal_walking[band], axis=(0, 1))  # Mean across epochs and channels\n",
    "    \n",
    "    # Perform a t-test\n",
    "    t_stat_psd, p_value_psd = stats.ttest_ind(mean_psd_mod, mean_psd_norm)\n",
    "    \n",
    "    # Store the results\n",
    "    t_stats_psd[band] = t_stat_psd\n",
    "    p_values_psd[band] = p_value_psd\n",
    "\n",
    "# Display results\n",
    "for band in t_stats_psd.keys():\n",
    "    print(f'Band: {band}, T-statistic: {t_stats_psd[band]:.4f}, P-value: {p_values_psd[band]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model (LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epochs.get_data().shape)\n",
    "print(epochs['mod_start'].get_data().shape)\n",
    "print(epochs['normal_walking'].get_data().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Assuming epochs are in the shape (n_epochs, n_channels, n_frequencies)\n",
    "# Convert your epochs data into a suitable format for classification\n",
    "# For this example, we'll use the 'mod_start' and 'normal_walking' classes\n",
    "\n",
    "# Load your data\n",
    "X_mod_start = epochs['mod_start'].get_data(copy=True)  # Shape: (147, 6, 501)\n",
    "X_normal_walking = epochs['normal_walking'].get_data(copy=True)  # Shape: (610, 6, 501)\n",
    "\n",
    "# Combine the data and create labels\n",
    "X = np.concatenate((X_mod_start, X_normal_walking), axis=0)  # Shape: (757, 6, 501)\n",
    "y = np.array([0] * X_mod_start.shape[0] + [1] * X_normal_walking.shape[0])  # 0 for mod_start, 1 for normal_walking\n",
    "\n",
    "# Flatten the data across channels and frequencies for classification\n",
    "n_epochs = X.shape[0]\n",
    "X_flat = X.reshape(n_epochs, -1)  # Shape: (757, 6 * 501)\n",
    "\n",
    "# Initialize Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Initialize model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Store the results\n",
    "scores = []\n",
    "\n",
    "# Perform Stratified K-Fold Cross-Validation\n",
    "for train_index, test_index in skf.split(X_flat, y):\n",
    "    X_train, X_test = X_flat[train_index], X_flat[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions and evaluate\n",
    "    predictions = model.predict(X_test)\n",
    "    score = accuracy_score(y_test, predictions)\n",
    "    scores.append(score)\n",
    "\n",
    "# Average accuracy across folds\n",
    "mean_score = np.mean(scores)\n",
    "print(f'Mean accuracy: {mean_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression  # Example model; you can replace it with your model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming X is your features and y are the labels\n",
    "X = epochs.get_data(copy=True).reshape(epochs.get_data(copy=True).shape[0], -1)  # Reshape to (n_epochs, n_channels * n_features)\n",
    "y = np.array([0] * epochs['mod_start'].get_data(copy=True).shape[0] + [1] * epochs['normal_walking'].get_data(copy=True).shape[0])  # Example labels\n",
    "\n",
    "# Initialize Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=5)  # You can choose any number of splits\n",
    "metrics = {\n",
    "    'accuracy': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'f1': [],\n",
    "    'confusion_matrices': []\n",
    "}\n",
    "\n",
    "# Stratified K-Fold Cross-Validation\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Optional: Scale your features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Train your model\n",
    "    model = LogisticRegression()  # Example model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics['accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    metrics['precision'].append(precision_score(y_test, y_pred, average='weighted'))\n",
    "    metrics['recall'].append(recall_score(y_test, y_pred, average='weighted'))\n",
    "    metrics['f1'].append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    metrics['confusion_matrices'].append(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Calculate mean and standard deviation for metrics\n",
    "for key in metrics:\n",
    "    if key != 'confusion_matrices':\n",
    "        print(f\"{key.capitalize()} - Mean: {np.mean(metrics[key]):.2f}, Std: {np.std(metrics[key]):.2f}\")\n",
    "    else:\n",
    "        # Print confusion matrices\n",
    "        for i, cm in enumerate(metrics['confusion_matrices']):\n",
    "            print(f\"Confusion Matrix for fold {i + 1}:\\n{cm}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs['mod_start'].get_data().shape, epochs['normal_walking'].get_data().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Temporal models - LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\", physical_devices)\n",
    "\n",
    "if physical_devices:\n",
    "    print(\"Using GPU\")\n",
    "    for gpu in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "else:\n",
    "    print(\"No GPU detected. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 1: Prepare the Data\n",
    "# Assuming epochs is already defined and contains your data.\n",
    "X_mod = epochs['mod_start'].get_data()  # Shape: (147, 6, 501)\n",
    "X_norm = epochs['normal_walking'].get_data()  # Shape: (610, 6, 501)\n",
    "\n",
    "# Stack your data\n",
    "X = np.concatenate([X_mod, X_norm], axis=0)  # Shape: (757, 6, 501)\n",
    "y = np.concatenate([np.zeros(X_mod.shape[0]), np.ones(X_norm.shape[0])])  # Labels: 0 for mod_start, 1 for normal_walking\n",
    "\n",
    "# Step 2: Define the LSTM Model\n",
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape=input_shape, return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # For binary classification\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Step 3: Stratified K-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "all_metrics = []\n",
    "\n",
    "# Step 4: Initialize a list to store history\n",
    "histories = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Reshape the data for LSTM input\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "    model = create_model((X_train.shape[1], X_train.shape[2]))\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "    # Step 5: Train the Model and save history\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=50,\n",
    "                        batch_size=32,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        # callbacks=[early_stopping],\n",
    "                        )\n",
    "    \n",
    "    histories.append(history.history)  # Store history for plotting\n",
    "    \n",
    "    # Step 6: Evaluate the Model\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")  # Threshold at 0.5 for binary classification\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    all_metrics.append((accuracy, precision, recall, f1))\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['mod_start', 'normal_walking'], yticklabels=['mod_start', 'normal_walking'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Plotting Learning Progress\n",
    "# Check minimum length of history entries\n",
    "min_length = min(len(history['loss']) for history in histories)\n",
    "\n",
    "# Truncate histories to the minimum length\n",
    "avg_train_loss = np.mean([history['loss'][:min_length] for history in histories], axis=0)\n",
    "avg_val_loss = np.mean([history['val_loss'][:min_length] for history in histories], axis=0)\n",
    "avg_train_accuracy = np.mean([history['accuracy'][:min_length] for history in histories], axis=0)\n",
    "avg_val_accuracy = np.mean([history['val_accuracy'][:min_length] for history in histories], axis=0)\n",
    "\n",
    "# Plot Loss\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(avg_train_loss, label='Train Loss', color='blue')\n",
    "plt.plot(avg_val_loss, label='Validation Loss', color='orange')\n",
    "plt.title('Loss Progression')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(avg_train_accuracy, label='Train Accuracy', color='blue')\n",
    "plt.plot(avg_val_accuracy, label='Validation Accuracy', color='orange')\n",
    "plt.title('Accuracy Progression')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw psd\n",
    "raw_spectrum = raw_data_clean.compute_psd(method='welch', fmin=1, fmax=50, n_fft=2048)\n",
    "\n",
    "psd_arr = raw_spectrum.get_data()\n",
    "psd_freqs = raw_spectrum.freqs\n",
    "print(raw_data_clean.get_data().shape)\n",
    "print(f\"PSD data has shape: {psd_arr.shape}  # channels x frequencies\")\n",
    "print(f\"Frequencies has shape: {psd_freqs.shape}  # frequencies\")\n",
    "\n",
    "raw_spectrum.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_spectrum.get_data().shape, raw_data_clean.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs psd: Train set\n",
    "train_epoch_spectrum = train_all_epochs_combined.compute_psd(method='welch', fmax=50)\n",
    "\n",
    "psd_arr = train_epoch_spectrum.get_data()\n",
    "psd_freqs = train_epoch_spectrum.freqs\n",
    "\n",
    "print(train_all_epochs_combined.get_data().shape)\n",
    "print(f\"PSD data has shape: {psd_arr.shape}\")\n",
    "print(f\"Frequencies has shape: {psd_freqs.shape}\")\n",
    "\n",
    "train_epoch_spectrum.plot(average=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch_spectrum['mod_start'].plot(average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch_spectrum['normal_walking'].plot(average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs psd: Test set\n",
    "test_epoch_spectrum = test_all_epochs_combined.compute_psd(method='welch', fmax=50)\n",
    "\n",
    "psd_arr = test_epoch_spectrum.get_data()\n",
    "psd_freqs = test_epoch_spectrum.freqs\n",
    "\n",
    "print(test_all_epochs_combined.get_data().shape)\n",
    "print(f\"PSD data has shape: {psd_arr.shape}\")\n",
    "print(f\"Frequencies has shape: {psd_freqs.shape}\")\n",
    "\n",
    "test_epoch_spectrum.plot(average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch_spectrum['mod_start'].plot(average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch_spectrum['normal_walking'].plot(average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_epochs_combined.get_data().shape, train_epoch_spectrum.get_data().shape\n",
    "\n",
    "\n",
    "\n",
    "# train_all_epochs_combined.events[:, -1].shape, test_all_epochs_combined.events[:, -1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression based on PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Step 1: Train-test split\n",
    "X_train = train_epoch_spectrum.get_data()\n",
    "X_test = test_epoch_spectrum.get_data()\n",
    "\n",
    "y_train = train_all_epochs_combined.events[:, -1]\n",
    "y_test = test_all_epochs_combined.events[:, -1]\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')# (n_epochs, n_channels, n_samples_per_epoch)\n",
    "print(f'y_train shape: {y_train.shape}')  # (n_epochs,)\n",
    "print(f'--- Total epochs: {len(y_train)}, with {sum(y_train == -1)} normal walking and {sum(y_train == 1)} event-related gait modulation')\n",
    "\n",
    "print(f'X_test shape: {X_test.shape}')# (n_epochs, n_channels, n_samples_per_epoch)\n",
    "print(f'y_test shape: {y_test.shape}')  # (n_epochs,)\n",
    "print(f'--- Total epochs: {len(y_train)}, with {sum(y_test == -1)} normal walking and {sum(y_test == 1)} event-related gait modulation')\n",
    "\n",
    "# Step 2: Flatten the X array (n_epochs, n_channels, n_samples_per_epoch) -> (n_epochs, n_channels * n_samples_per_epoch)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])\n",
    "\n",
    "\n",
    "# Step 3: Standardize the features (mean=0, std=1)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 4: Train a Logistic Regression model\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 5: Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Output the results\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Output the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICA raw\n",
    "## CODE GOES HERE\n",
    "ica_95PCA = mne.preprocessing.ICA(n_components=0.95, random_state=0)\n",
    "ica_95PCA.fit(inst=lfp_raw)\n",
    "# ica_95PCA.plot_sources(inst=lfp_raw, title=\"ICA sources (95% variance PCA components)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_ica_excluded = ica.apply(inst=lfp_raw.copy())\n",
    "# raw_ica = ica.apply(inst=lfp_raw.copy())\n",
    "\n",
    "# raw_ica_excluded.plot(scalings='auto', start=12, duration=4, title='clraned sensor signals (without noise)')\n",
    "# raw_ica.plot(scalings='auto', start=12, duration=4, title='clraned sensor signals (without noise)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ICA rpochs\n",
    "# ## CODE GOES HERE\n",
    "# ica_95PCA = mne.preprocessing.ICA(n_components=0.95, random_state=0)\n",
    "# ica_95PCA.fit(inst=epochs_raw)\n",
    "# ica_95PCA.plot_sources(inst=epochs_raw, title=\"ICA sources (95% variance PCA components)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute variance explained by PCA components\n",
    "# explained_variance = ica.pca_explained_variance_ / np.sum(ica.pca_explained_variance_)\n",
    "\n",
    "# print(f\"Variance explained by PCA components: {explained_variance}\")\n",
    "# print(f\"Variance explained by first 4 PCA components: {np.sum(explained_variance[:4]) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ica = mne.preprocessing.ICA(random_state=0)\n",
    "# ica.fit(raw_sensors)\n",
    "\n",
    "# # Remove the first ICA component (the random noise) from the data\n",
    "# raw_cleaned = ica.apply(inst=raw_sensors.copy(), exclude=[1,2])\n",
    "# raw_cleaned.plot(scalings='auto', title='clraned sensor signals (without noise)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_raw[\"mod_start\"].plot_image(combine=\"mean\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_epochs_image(\n",
    "    epochs_raw['mod_start'],\n",
    "    picks=[0, 1, 2, 3, 4, 5],\n",
    "    sigma=0.5,\n",
    "    # combine=\"mean\",\n",
    "    # evoked=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evoked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evoked_0 = epochs_raw['trial_start'].average()\n",
    "evoked_4 = epochs_raw['mod_start'].average()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Field Power (GFP)\n",
    "\n",
    "The GFP is the population standard deviation of the signal across channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig0 = evoked_0.plot(gfp=True);\n",
    "fig1 = evoked_1.plot(gfp=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked_0.plot(gfp=\"only\");\n",
    "evoked_1.plot(gfp=\"only\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfp = evoked_0.data.std(axis=0, ddof=0)\n",
    "\n",
    "# Reproducing the MNE-Python plot style seen above\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(evoked_0.times, gfp * 1e6, color=\"lime\")\n",
    "ax.fill_between(evoked_0.times, gfp * 1e6, color=\"lime\", alpha=0.2)\n",
    "ax.set(xlabel=\"Time (s)\", ylabel=\"GFP (µV)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfp = evoked_1.data.std(axis=0, ddof=0)\n",
    "\n",
    "# Reproducing the MNE-Python plot style seen above\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(evoked_1.times, gfp * 1e6, color=\"lime\")\n",
    "ax.fill_between(evoked_1.times, gfp * 1e6, color=\"lime\", alpha=0.2)\n",
    "ax.set(xlabel=\"Time (s)\", ylabel=\"GFP (µV)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Time-frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.arange(2, 50, 2) # Frequencies from 2 to 50 Hz\n",
    "n_cycles = freqs / 2 # Number of cycles in Morlet wavelet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.arange(7, 30, 3)\n",
    "power = epochs_raw['mod_start'].compute_tfr(\n",
    "    \"morlet\", \n",
    "    n_cycles=2,\n",
    "    return_itc=False, \n",
    "    freqs=freqs,\n",
    "    decim=3,\n",
    "    average=True\n",
    ")\n",
    "power.plot(title='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.arange(7, 30, 3)\n",
    "power = epochs_raw['min_vel'].compute_tfr(\n",
    "    \"morlet\", \n",
    "    n_cycles=2,\n",
    "    return_itc=False, \n",
    "    freqs=freqs,\n",
    "    decim=3,\n",
    "    average=True\n",
    ")\n",
    "power.plot(title='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csd_fft = mne.time_frequency.csd_fourier(train_all_epochs_combined, fmin=1, fmax=50)\n",
    "csd_mt = mne.time_frequency.csd_multitaper(train_all_epochs_combined, fmin=1, fmax=50, adaptive=True)\n",
    "frequencies = np.arange(1,51, 1)\n",
    "csd_wav = mne.time_frequency.csd_morlet(train_all_epochs_combined, frequencies, decim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dict = {\n",
    "    \"Short-time Fourier transform\": csd_fft,\n",
    "    \"Adaptive multitapers\": csd_mt,\n",
    "    \"Morlet wavelet transform\": csd_wav,\n",
    "}\n",
    "for title, csd in plot_dict.items():\n",
    "    (fig,) = csd.mean().plot()\n",
    "    fig.suptitle(title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gait_modulation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
